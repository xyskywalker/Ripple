#!/usr/bin/env python3
# =============================================================================
# e2e_ab_test_fmcg_coffee.py â€”â€” A/B æµ‹è¯•ï¼šå†»å¹²å’–å•¡å®šä½ç­–ç•¥ Ã— æŠ–éŸ³ç”µå•† PMF éªŒè¯ / A/B test: freeze-dried coffee positioning strategy Ã— Douyin PMF validation
#
# æµ‹è¯•å‡è®¾ï¼šç›¸åŒåŸºåº•äº§å“ä»…æ”¹å˜å®šä½ç­–ç•¥ï¼Œè§‚å¯Ÿ PMF æ˜¯å¦æ˜¾è‘—å·®å¼‚ã€‚ / Hypothesis: same base product with different positioning may produce significantly different PMF performance.
#
#   Aç»„ï¼ˆé»‘é•œÂ·é›¶æ„Ÿï¼‰: "çœŸ0æ·»åŠ â€”â€”0ç³–0è„‚0å¡0ä»£ç³–" â†’ å¥åº·ç„¦è™‘é©±åŠ¨ / Group A: health-anxiety driven positioning
#   Bç»„ï¼ˆé»‘é•œÂ·äº‘å—ï¼‰: "äº‘å—ä¿å±±å•ä¸€äº§åœ° SCA 85+"  â†’ å“è´¨æº¢ä»·é©±åŠ¨ / Group B: quality-premium driven positioning
#
# æ§åˆ¶å˜é‡ï¼šå“ç‰Œã€ä»·æ ¼ã€è§„æ ¼ã€æ¸ é“ã€æŠ•æ”¾æ—¶æ®µã€ç›®æ ‡äººç¾¤ã€‚ / Controlled variables: brand, price, package size, channel, launch window, and target persona.
# å”¯ä¸€è‡ªå˜é‡ï¼šæ ¸å¿ƒå®šä½ç­–ç•¥ï¼ˆå¥åº·ç„¦è™‘ vs å“è´¨æº¯æºï¼‰ã€‚ / Independent variable: core positioning strategy.
#
# ç”¨æ³• / Usage:
#   python examples/e2e_ab_test_fmcg_coffee.py a              # ä»…è¿è¡ŒAç»„
#   python examples/e2e_ab_test_fmcg_coffee.py b              # ä»…è¿è¡ŒBç»„
#   python examples/e2e_ab_test_fmcg_coffee.py ab             # åŒç»„ + A/Bå¯¹æ¯”æŠ¥å‘Š
#   python examples/e2e_ab_test_fmcg_coffee.py ab --waves 4   # å¿«é€Ÿè¯•è·‘
#   python examples/e2e_ab_test_fmcg_coffee.py compare \
#     --file-a ripple_outputs/xxx_a.md \
#     --file-b ripple_outputs/xxx_b.md                        # ä»å·²æœ‰ç»“æœç›´æ¥å¯¹æ¯”
# =============================================================================

from __future__ import annotations

import asyncio
import json
import logging
import re
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from e2e_helpers import (
    ReportRound,
    build_historical_from_posts,
    call_llm,
    config_file_path,
    create_arg_parser,
    format_stats_block,
    load_simulation_log,
    print_compact_log,
    print_progress,
    print_result_summary,
    run_and_interpret,
    setup_logging,
    simulate,
    REPO_ROOT,
)
from ripple.llm.router import ModelRouter

setup_logging()
logger = logging.getLogger(__name__)

# =============================================================================
# å¸¸é‡é…ç½® / Constants
# =============================================================================
SKILL_NAME = "pmf-validation"
CHANNEL = "algorithm-ecommerce"
VERTICAL = "fmcg"
PLATFORM = "douyin"
SIMULATION_HOURS = 72
DEFAULT_WAVES = SIMULATION_HOURS // 3  # æ¯ä¸ª wave â‰ˆ 3å°æ—¶
MAX_LLM_CALLS = 1000
ENSEMBLE_RUNS = 1
DELIBERATION_ROUNDS = 3

# =============================================================================
# A ç»„äº§å“å®šä¹‰ï¼ˆé»‘é•œÂ·é›¶æ„Ÿï¼‰ / Group A product definition (HEIJING Zero)
# =============================================================================
PRODUCT_A: Dict[str, Any] = {
    "name": "é»‘é•œÂ·é›¶æ„Ÿå†»å¹²é»‘å’–å•¡",
    "category": "å†»å¹²å³æº¶å’–å•¡",
    "brand": "é»‘é•œï¼ˆHEIJINGï¼‰",
    "description": (
        "é»‘é•œÂ·é›¶æ„Ÿæ˜¯ä¸€æ¬¾ä¸»æ‰“'çœŸ0æ·»åŠ 'æ¦‚å¿µçš„å†»å¹²å³æº¶é»‘å’–å•¡ã€‚"
        "åŒºåˆ«äºå¸‚é¢ä¸Šä½¿ç”¨èµ¤è—“ç³–é†‡ã€ç”œèŠç³–è‹·ç­‰ä»£ç³–æ–¹æ¡ˆçš„'ä¼ª0ç³–'äº§å“ï¼Œ"
        "é›¶æ„Ÿçš„é…æ–™è¡¨åªæœ‰ä¸€è¡Œï¼š100%é˜¿æ‹‰æ¯”å¡å’–å•¡èƒå–å†»å¹²ç²‰ã€‚"
        "æ ¸å¿ƒå–ç‚¹'0ç³–0è„‚0å¡0ä»£ç³–'ç›´å‡»å½“ä¸‹æ¶ˆè´¹è€…å¯¹éšæ€§æ·»åŠ çš„ç„¦è™‘ã€‚"
        "ç›®æ ‡äººç¾¤ä¸º25-35å²æ³¨é‡èº«æç®¡ç†å’Œæˆåˆ†é€æ˜çš„éƒ½å¸‚ç™½é¢†ã€å¥èº«äººç¾¤ã€‚"
        "è§„æ ¼ä¸º2gÃ—10é¢—è¿·ä½ ç½è£…ï¼ŒåŒ…è£…é‡‡ç”¨å“‘å…‰é»‘+è§å…‰ç»¿é…è‰²ï¼Œå¼ºè°ƒå¥åº·æ´»åŠ›æ„Ÿã€‚"
        "å»ºè®®é›¶å”®ä»·59.9å…ƒ/ç›’ï¼ˆ5.99å…ƒ/æ¯ï¼‰ï¼ŒæŠ–éŸ³é¦–å‘ä»·39.9å…ƒ/ç›’ï¼ˆ3.99å…ƒ/æ¯ï¼‰ã€‚"
        "é¦–å‘æ¸ é“ä¸ºæŠ–éŸ³ç”µå•†ï¼ˆçŸ­è§†é¢‘ç§è‰+å“ç‰Œè‡ªæ’­+è¾¾äººçŸ©é˜µåˆ†é”€ï¼‰ï¼Œ"
        "å†…å®¹ç­–ç•¥ä¸»æ‰“'é…æ–™è¡¨åªæœ‰ä¸€è¡Œ'çš„è§†è§‰å†²å‡»å’Œæˆåˆ†å¯¹æ¯”ã€‚"
    ),
    "price": "59.9å…ƒ/ç›’ï¼ˆ2gÃ—10é¢—ï¼‰ï¼ŒæŠ–éŸ³é¦–å‘ä»·39.9å…ƒ/ç›’ï¼ˆé™æ—¶7å¤©ï¼‰",
    "differentiators": [
        "çœŸ0æ·»åŠ ï¼šé…æ–™è¡¨ä»…ä¸€è¡Œï¼ˆ100%é˜¿æ‹‰æ¯”å¡å†»å¹²ç²‰ï¼‰ï¼Œ0ç³–0è„‚0å¡ä¸”0ä»£ç³–",
        "æˆåˆ†é€æ˜ï¼šæ¯ç½å°æœ‰å®Œæ•´è¥å…»æˆåˆ†æ£€æµ‹æŠ¥å‘ŠäºŒç»´ç ",
        "æç®€åŒ…è£…ï¼šå“‘å…‰é»‘+è§å…‰ç»¿è¿·ä½ ç½ï¼Œé…æ–™è¡¨å åŒ…è£…æ­£é¢50%é¢ç§¯",
        "å¥åº·èƒŒä¹¦ï¼šè·ä¸­å›½è¥å…»å­¦ä¼š'æ¸…æ´æ ‡ç­¾'è®¤è¯",
    ],
    "competitive_landscape": (
        "ç›´æ¥ç«å“ï¼šä¸‰é¡¿åŠï¼ˆå†»å¹²å’–å•¡å“ç±»å¼€åˆ›è€…ï¼Œä½†ä½¿ç”¨èµ¤è—“ç³–é†‡è°ƒå‘³æ¬¾å æ¯”40%ï¼‰ã€"
        "éš…ç”°å·ï¼ˆä¸»åŠ›ä¸ºæŒ‚è€³å’Œæ¶²ä½“å’–å•¡ï¼Œå†»å¹²çº¿éæ ¸å¿ƒï¼‰ã€"
        "æ°¸ç’ï¼ˆè®¾è®¡é©±åŠ¨ï¼Œå†»å¹²çº¿å£å‘³åç”œï¼‰ã€"
        "ç‘å¹¸å†»å¹²ï¼ˆä»·æ ¼æ€æ‰‹ï¼Œä½†å“æ§äº‰è®®å¤šï¼‰ã€‚"
        "é—´æ¥ç«å“ï¼šæ‰€æœ‰ä¸»æ‰“'0ç³–'æ¦‚å¿µçš„é¥®å“å’Œä»£é¤äº§å“ã€‚"
        "å“ç±»ç°çŠ¶ï¼šå†»å¹²å’–å•¡èµ›é“å·²ä»è“æµ·è½¬ä¸ºçº¢æµ·ï¼Œä¸‰é¡¿åŠä¸€å®¶ç‹¬å¤§ï¼Œ"
        "ä½†'çœŸ0æ·»åŠ 'ç»†åˆ†èµ›é“å°šæ— å¼ºåŠ¿å“ç‰Œå ä½ã€‚"
    ),
}

# =============================================================================
# B ç»„äº§å“å®šä¹‰ï¼ˆé»‘é•œÂ·äº‘å—ï¼‰ / Group B product definition (HEIJING Yunnan)
# =============================================================================
PRODUCT_B: Dict[str, Any] = {
    "name": "é»‘é•œÂ·äº‘å—å†»å¹²ç²¾å“å’–å•¡",
    "category": "å†»å¹²å³æº¶å’–å•¡",
    "brand": "é»‘é•œï¼ˆHEIJINGï¼‰",
    "description": (
        "é»‘é•œÂ·äº‘å—æ˜¯ä¸€æ¬¾ä¸»æ‰“'ç²¾å“äº§åœ°æº¯æº'æ¦‚å¿µçš„å†»å¹²å³æº¶å’–å•¡ã€‚"
        "ç²¾é€‰äº‘å—ä¿å±±é«˜é»è´¡å±±æµ·æ‹”1800-2100ç±³çš„å°ç²’ç§é˜¿æ‹‰æ¯”å¡å’–å•¡è±†ï¼Œ"
        "ç»SCAï¼ˆç²¾å“å’–å•¡åä¼šï¼‰æ¯æµ‹è¯„åˆ†è¾¾85+ï¼Œå±ç²¾å“çº§ï¼ˆSpecialty Gradeï¼‰ã€‚"
        "æ¯ç½å°æœ‰ç§æ¤åº„å›­ç¼–å·ã€é‡‡æ‘˜æ‰¹æ¬¡å’Œæµ·æ‹”ä¿¡æ¯ï¼Œå®ç°å…¨é“¾è·¯æº¯æºã€‚"
        "æ ¸å¿ƒå–ç‚¹'ä»æµ·æ‹”2000ç±³åˆ°ä½ çš„æ¯ä¸­'ä¸»æ‰“å›½äº§ç²¾å“å’–å•¡çš„å“è´¨å™äº‹ã€‚"
        "ç›®æ ‡äººç¾¤ä¸º25-35å²è¿½æ±‚å“è´¨ç”Ÿæ´»çš„éƒ½å¸‚ç™½é¢†ã€ç²¾å“å’–å•¡å…¥é—¨ç”¨æˆ·ã€‚"
        "è§„æ ¼ä¸º2gÃ—10é¢—è¿·ä½ ç½è£…ï¼ŒåŒ…è£…é‡‡ç”¨å“‘å…‰é»‘+å¤§åœ°æ£•é…è‰²ï¼Œå¼ºè°ƒäº§åœ°è‡ªç„¶æ„Ÿã€‚"
        "å»ºè®®é›¶å”®ä»·59.9å…ƒ/ç›’ï¼ˆ5.99å…ƒ/æ¯ï¼‰ï¼ŒæŠ–éŸ³é¦–å‘ä»·39.9å…ƒ/ç›’ï¼ˆ3.99å…ƒ/æ¯ï¼‰ã€‚"
        "é¦–å‘æ¸ é“ä¸ºæŠ–éŸ³ç”µå•†ï¼ˆçŸ­è§†é¢‘ç§è‰+å“ç‰Œè‡ªæ’­+è¾¾äººçŸ©é˜µåˆ†é”€ï¼‰ï¼Œ"
        "å†…å®¹ç­–ç•¥ä¸»æ‰“äº§åœ°æº¯æºçºªå½•ç‰‡é£æ ¼å’Œå’–å•¡é£å‘³è½®è§£æã€‚"
    ),
    "price": "59.9å…ƒ/ç›’ï¼ˆ2gÃ—10é¢—ï¼‰ï¼ŒæŠ–éŸ³é¦–å‘ä»·39.9å…ƒ/ç›’ï¼ˆé™æ—¶7å¤©ï¼‰",
    "differentiators": [
        "å•ä¸€äº§åœ°æº¯æºï¼šäº‘å—ä¿å±±é«˜é»è´¡å±±å°ç²’ç§ï¼Œæ¯ç½æ ‡æ³¨åº„å›­ç¼–å·å’Œæµ·æ‹”",
        "ç²¾å“çº§è®¤è¯ï¼šSCAæ¯æµ‹è¯„åˆ†85+ï¼Œå…·å¤‡èŠ±é¦™ã€æŸ‘æ©˜ã€çº¢ç³–é£å‘³å±‚æ¬¡",
        "äº§åœ°ç›´é‡‡ï¼šä¸å½“åœ°å’–å•¡åˆä½œç¤¾ç­¾çº¦ï¼Œä»é‡‡æ‘˜åˆ°å†»å¹²å…¨ç¨‹72å°æ—¶å®Œæˆ",
        "å“è´¨å™äº‹ï¼šåŒ…è£…å†…é™„äº§åœ°æ˜ä¿¡ç‰‡å’Œé£å‘³è½®å¡ç‰‡ï¼Œå¢å¼ºä»ªå¼æ„Ÿ",
    ],
    "competitive_landscape": (
        "ç›´æ¥ç«å“ï¼šä¸‰é¡¿åŠï¼ˆä»¥æ‹¼é…ä¸ºä¸»ï¼Œå•ä¸€äº§åœ°æ¬¾ä¸ºé™é‡ç³»åˆ—éå¸¸è§„SKUï¼‰ã€"
        "éš…ç”°å·ï¼ˆä¸»æ‰“ä¾¿æ·æ€§ï¼Œæœªå¼ºè°ƒäº§åœ°æ•…äº‹ï¼‰ã€"
        "æ°¸ç’ï¼ˆè®¾è®¡å’Œè”åé©±åŠ¨ï¼Œäº§åœ°å™äº‹è–„å¼±ï¼‰ã€"
        "ç‘å¹¸å†»å¹²ï¼ˆä»·æ ¼å¯¼å‘ï¼Œæ— äº§åœ°æº¢ä»·ç©ºé—´ï¼‰ã€‚"
        "é—´æ¥ç«å“ï¼šçº¿ä¸‹ç²¾å“å’–å•¡é¦†çš„é›¶å”®è±†/æŒ‚è€³äº§å“ï¼ˆå¦‚Mannerã€Seesawï¼‰ã€‚"
        "å“ç±»ç°çŠ¶ï¼šå†»å¹²å’–å•¡èµ›é“ç«äº‰æ¿€çƒˆï¼Œä½†'å•ä¸€äº§åœ°å¯æº¯æº'å®šä½åœ¨å³æº¶å“ç±»ä¸­"
        "ä»å±å·®å¼‚åŒ–ç©ºç™½ï¼Œç²¾å“å’–å•¡'ç¬¬å››æ³¢æµªæ½®'çš„äº§åœ°å™äº‹å°šæœªè¢«å†»å¹²å“ç‰Œå……åˆ†å ä½ã€‚"
    ),
}

# =============================================================================
# å…±äº«å“ç‰Œè´¦å·ï¼ˆä¸¤ç»„ä½¿ç”¨ç›¸åŒè´¦å·åŸºçº¿ï¼‰
# =============================================================================
BRAND_ACCOUNT: Dict[str, Any] = {
    "account_name": "é»‘é•œå’–å•¡å®˜æ–¹æ——èˆ°åº—",
    "bio": "ä¸€æ¯å¥½å’–å•¡ï¼Œä¸éœ€è¦è§£é‡Š | æ–°é”å†»å¹²å’–å•¡å“ç‰Œ",
    "platform_code": PLATFORM,
    "main_category": "é£Ÿå“é¥®æ–™",
    "content_style": "é«˜çº§è´¨æ„Ÿã€äº§å“ç‰¹å†™+åœºæ™¯åŒ–ã€å¼ºè°ƒå“è´¨ç»†èŠ‚",
    "target_audience": "25-35å²éƒ½å¸‚ç™½é¢†ã€å’–å•¡çˆ±å¥½è€…ã€å“è´¨ç”Ÿæ´»è¿½æ±‚è€…",
    "followers_count": 12000,
    "posts_count": 18,
    "verification_status": "enterprise",
    "started_at": "2025-11-15",
}

# =============================================================================
# å…±äº«å†å²æ•°æ®ï¼ˆå“ç‰Œé€šç”¨å†…å®¹ï¼Œä¸åå‘ä»»ä¸€å®šä½ï¼‰
# =============================================================================
HISTORICAL_POSTS: List[Dict[str, Any]] = [
    {
        "title": "å†»å¹²å’–å•¡ç›²æµ‹PKï¼šé»‘é•œ vs ä¸‰é¡¿åŠ vs éš…ç”°å·",
        "content": "æ‰¾äº†8ä¸ªåŒäº‹åšç›²æµ‹ï¼Œ3æ¬¾å†»å¹²å’–å•¡ä¸è´´æ ‡ç­¾ç›´æ¥å†²æ³¡å“é‰´...",
        "post_type": "çŸ­è§†é¢‘",
        "views": 180000, "likes": 7200, "comments": 560,
        "shares": 420, "sales": 95, "gmv": 3800, "return_rate": 0.03,
    },
    {
        "title": "é…æ–™è¡¨ç¿»è½¦ç°åœºï¼š10æ¬¾å†»å¹²å’–å•¡æˆåˆ†å¤§èµ·åº•",
        "content": "ä¹°äº†å¸‚é¢ä¸Š10æ¬¾å†»å¹²å’–å•¡ï¼Œé€ä¸€æ‹†è§£é…æ–™è¡¨å’Œè¥å…»æˆåˆ†...",
        "post_type": "çŸ­è§†é¢‘",
        "views": 320000, "likes": 15000, "comments": 1200,
        "shares": 890, "sales": 210, "gmv": 8400, "return_rate": 0.02,
    },
    {
        "title": "2å—é’±ä¸€æ¯çš„å†»å¹² vs 30å—çš„æ‰‹å†²ï¼Œç›²æµ‹ç»“æœæ„å¤–äº†",
        "content": "æ‰¾äº†ä¸“ä¸šå’–å•¡å¸ˆå’Œæ™®é€šæ¶ˆè´¹è€…å„5äººï¼Œç›²æµ‹æ‰“åˆ†...",
        "post_type": "çŸ­è§†é¢‘",
        "views": 250000, "likes": 11000, "comments": 980,
        "shares": 650, "sales": 150, "gmv": 6000, "return_rate": 0.04,
    },
    {
        "title": "æ‰“å·¥äººç»­å‘½æŒ‡å—ï¼šåŠå…¬å®¤å†»å¹²å’–å•¡å†²æ³¡çš„5ç§æ–¹æ³•",
        "content": "å†°ç¾å¼ã€ç‡•éº¦æ‹¿é“ã€æ°”æ³¡ç¾å¼ã€æ¤°å¥¶dirtyã€å†°åšå…‹...",
        "post_type": "çŸ­è§†é¢‘",
        "views": 95000, "likes": 4200, "comments": 350,
        "shares": 280, "sales": 65, "gmv": 2600, "return_rate": 0.02,
    },
    {
        "title": "ã€ç›´æ’­å›æ”¾ã€‘é»‘é•œå†»å¹²å’–å•¡å“ç‰Œé¦–åœºè‡ªæ’­",
        "content": "å“ç‰Œé¦–åœºè‡ªæ’­ï¼Œä¸»æ’­è¯¦ç»†è®²è§£å†»å¹²å·¥è‰ºå’Œå“ç‰Œç†å¿µ...",
        "post_type": "ç›´æ’­",
        "views": 28000, "likes": 850, "comments": 420,
        "shares": 65, "sales": 180, "gmv": 7200, "return_rate": 0.06,
    },
    {
        "title": "æ¢è®¿äº‘å—å’–å•¡åº„å›­ï¼šä»å’–å•¡æ¨±æ¡ƒåˆ°å†»å¹²çš„72å°æ—¶",
        "content": "è·Ÿç€é•œå¤´æ·±å…¥äº‘å—ä¿å±±é«˜é»è´¡å±±ï¼Œè®°å½•å’–å•¡è±†ä»é‡‡æ‘˜åˆ°å†»å¹²å…¨è¿‡ç¨‹...",
        "post_type": "çŸ­è§†é¢‘",
        "views": 140000, "likes": 6500, "comments": 480,
        "shares": 520, "sales": 85, "gmv": 3400, "return_rate": 0.02,
    },
]


# =============================================================================
# æ•°æ®æ„å»ºå™¨ï¼ˆPMF éªŒè¯ä¸“ç”¨ï¼‰ / Data builders for PMF validation
# =============================================================================

def _build_event(product: Dict[str, Any], group_label: str) -> Dict[str, Any]:
    """ä»äº§å“å®šä¹‰æ„å»º simulate() çš„ event å‚æ•°ã€‚ / Build simulate() event payload from product definition."""
    name = product.get("name", "")
    category = product.get("category", "")
    description = product.get("description", "")
    price = product.get("price", "")
    diffs = product.get("differentiators", [])

    parts = [f"äº§å“ï¼š{name}", f"å“ç±»ï¼š{category}", f"å®šä»·ï¼š{price}"]
    if diffs:
        parts.append(f"æ ¸å¿ƒå·®å¼‚ç‚¹ï¼š{'ã€'.join(diffs)}")
    if description:
        parts.append(f"äº§å“æè¿°ï¼š{description[:500]}")

    return {
        "title": f"[A/Bæµ‹è¯•-{group_label}ç»„] {name} â€” æŠ–éŸ³ç”µå•† PMF éªŒè¯",
        "description": description,
        "product_name": name,
        "category": category,
        "price": price,
        "differentiators": diffs,
        "competitive_landscape": product.get("competitive_landscape", ""),
        "target_channel": "æŠ–éŸ³ç”µå•†ï¼ˆç®—æ³•æ¨èæµ + ç›´æ’­å¸¦è´§ï¼‰",
        "validation_question": (
            f"'{name}'ä½œä¸ºä¸€æ¬¾{category}æ–°å“ï¼Œ"
            f"æ ¸å¿ƒå·®å¼‚åŒ–å®šä½ä¸ºã€Œ{'ï¼›'.join(diffs[:2])}ã€ï¼Œ"
            f"é€šè¿‡æŠ–éŸ³ç”µå•†æ¸ é“èƒ½å¦éªŒè¯ PMFï¼Ÿ"
            f"æ¶ˆè´¹è€…åœ¨ç®—æ³•æ¨èä¸‹å•åæ˜¯å¦ä¼šäº§ç”ŸçœŸå®å¤è´­éœ€æ±‚ï¼Ÿ"
            f"è¯¥å®šä½èƒ½å¦åœ¨ä¸‰é¡¿åŠã€éš…ç”°å·ä¸»å¯¼çš„å†»å¹²å’–å•¡çº¢æµ·ä¸­å»ºç«‹ç‹¬ç«‹å¿ƒæ™ºï¼Ÿ"
        ),
        "summary": " | ".join(parts),
    }


def _build_source(brand: Dict[str, Any]) -> Dict[str, Any]:
    """ä»å“ç‰Œè´¦å·æ„å»º simulate() çš„ source å‚æ•°ã€‚ / Build simulate() source payload from brand account."""
    name = brand.get("account_name", "")
    bio = brand.get("bio", "")
    followers = brand.get("followers_count", 0)
    style = brand.get("content_style", "")

    return {
        "account_name": name,
        "bio": bio,
        "platform_code": PLATFORM,
        "main_category": brand.get("main_category", ""),
        "content_style": style,
        "target_audience": brand.get("target_audience", ""),
        "followers_count": followers,
        "posts_count": brand.get("posts_count", 0),
        "verification_status": brand.get("verification_status", "enterprise"),
        "summary": (
            f"å“ç‰Œè´¦å·ï¼š{name} | ç²‰ä¸æ•°ï¼š{followers} | "
            f"å†…å®¹é£æ ¼ï¼š{style}" + (f" | ç®€ä»‹ï¼š{bio}" if bio else "")
        ),
    }


# =============================================================================
# å•ç»„ PMF æŠ¥å‘Šæç¤ºè¯ï¼ˆa / b å•ç‹¬è¿è¡Œæ—¶ä½¿ç”¨ï¼‰
# =============================================================================

_INDIVIDUAL_SYSTEM_PREFIX = (
    "ä½ æ˜¯ Ripple CASï¼ˆå¤æ‚è‡ªé€‚åº”ç³»ç»Ÿï¼‰PMF éªŒè¯æ¨¡æ‹Ÿå¼•æ“çš„ä¸“ä¸šåˆ†æå¸ˆã€‚\n"
    "ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæ¨¡æ‹Ÿå¼•æ“è¾“å‡ºçš„ç»“æ„åŒ–æ•°æ®ï¼Œç”Ÿæˆäººç±»å‹å¥½çš„ PMF éªŒè¯è§£è¯»æŠ¥å‘Šã€‚\n\n"
    "ã€æ ¼å¼è§„èŒƒã€‘\n"
    "- ä¸€å¾‹ä½¿ç”¨ç®€ä½“ä¸­æ–‡è¾“å‡º\n"
    "- ç”¨ã€ã€‘æ ‡è®°ç« èŠ‚æ ‡é¢˜\n"
    "- ä¸è¾“å‡º JSONã€ä»£ç å—æˆ– Markdown æ ¼å¼ï¼Œåªè¾“å‡ºçº¯æ–‡æœ¬\n"
    "- æ®µè½æ¸…æ™°ã€é€»è¾‘è¿è´¯ï¼Œå¯ç›´æ¥å±•ç¤ºç»™åˆ›ä¸šå›¢é˜Ÿ/äº§å“å›¢é˜Ÿé˜…è¯»\n\n"
    "ã€Agent å‘½åè§„èŒƒã€‘\n"
    "- å¸¦ star_ å‰ç¼€çš„ Agent æ˜¾ç¤ºä¸ºã€Œæ˜Ÿ-ã€+ ä¸­æ–‡æè¿°\n"
    "- å¸¦ sea_ å‰ç¼€çš„ Agent æ˜¾ç¤ºä¸ºã€Œæµ·-ã€+ ä¸­æ–‡æè¿°\n\n"
    "ã€PMF éªŒè¯è§†è§’ã€‘\n"
    "- å§‹ç»ˆåŒºåˆ†'ä¿ƒé”€é©±åŠ¨'ä¸'éœ€æ±‚é©±åŠ¨'çš„è¡Œä¸º\n"
    "- å§‹ç»ˆåŒºåˆ†'å†²åŠ¨æ¶ˆè´¹'ä¸'ç†æ€§é€‰æ‹©'çš„ä¿¡å·\n"
    "- å¯¹ç®—æ³•æ¨èç”µå•†æ¸ é“ï¼Œé‡ç‚¹å…³æ³¨å¤è´­ç‡è€Œéé¦–è´­é‡\n"
    "- è­¦æƒ•å°†'ç®—æ³•ç»™çš„æµé‡'è¯¯è¯»ä¸º'å¸‚åœºè‡ªå‘éœ€æ±‚'\n"
)


def _build_individual_report_rounds() -> List[ReportRound]:
    """æ„å»ºå•ç»„ PMF æŠ¥å‘Šè§„èŒƒï¼ˆ3è½®ï¼‰ã€‚ / Build single-group PMF report specification (3 rounds)."""
    extra_context = ""
    stats_text = format_stats_block(
        HISTORICAL_POSTS,
        metrics=("views", "likes", "comments", "shares", "sales"),
    )
    if stats_text:
        extra_context = f"## è¡¥å……ï¼šå†å²æ•°æ®ç»Ÿè®¡\n{stats_text}"

    return [
        ReportRound(
            label="éªŒè¯èƒŒæ™¯ä¸æ¨¡æ‹Ÿç¯å¢ƒ",
            system_prompt=_INDIVIDUAL_SYSTEM_PREFIX + (
                "å½“å‰ä»»åŠ¡ï¼šæ’°å†™ PMF éªŒè¯æŠ¥å‘Šçš„å‰ä¸¤ä¸ªç« èŠ‚ã€‚\n\n"
                "ã€éªŒè¯èƒŒæ™¯ã€‘ï¼ˆ100-150å­—ï¼‰\n"
                "æ¦‚è¿°æœ¬æ¬¡ PMF éªŒè¯çš„èƒŒæ™¯ï¼šéªŒè¯ä»€ä¹ˆäº§å“ã€æ ¸å¿ƒå®šä½ã€"
                "æ‰€å±è¡Œä¸šç‰¹å¾ã€ç›®æ ‡æ¸ é“ã€‚\n\n"
                "ã€æ¨¡æ‹Ÿç¯å¢ƒè®¾å®šã€‘ï¼ˆ200-300å­—ï¼‰\n"
                "è§£è¯»å…¨è§†è€…åœ¨åˆå§‹åŒ–é˜¶æ®µçš„ç¯å¢ƒè®¾å®šã€‚\n"
            ),
            extra_user_context=extra_context,
        ),
        ReportRound(
            label="ä¼ æ’­è¿‡ç¨‹ä¸ PMF ä¿¡å·",
            system_prompt=_INDIVIDUAL_SYSTEM_PREFIX + (
                "å½“å‰ä»»åŠ¡ï¼šæ’°å†™ PMF éªŒè¯æŠ¥å‘Šçš„ä¸­é—´ä¸¤ä¸ªç« èŠ‚ã€‚\n\n"
                "ã€ä¼ æ’­è¿‡ç¨‹å›é¡¾ã€‘ï¼ˆ150-250å­—ï¼‰\n"
                "æ¦‚è¿°ç®—æ³•æ¨èç”µå•†æ¸ é“ä¸­çš„ä¼ æ’­å…¨è²Œã€‚\n\n"
                "ã€PMF ä¿¡å·è¯†åˆ«ã€‘ï¼ˆ200-350å­—ï¼‰\n"
                "ä¸¥æ ¼åŒºåˆ†å¼º PMF ä¿¡å·ã€å¼± PMF ä¿¡å·ã€ä¼ª PMF ä¿¡å·ã€‚\n"
            ),
        ),
        ReportRound(
            label="PMF è¯„çº§ä¸è¡ŒåŠ¨å»ºè®®",
            system_prompt=_INDIVIDUAL_SYSTEM_PREFIX + (
                "å½“å‰ä»»åŠ¡ï¼šæ’°å†™ PMF éªŒè¯æŠ¥å‘Šçš„æœ€åä¸¤ä¸ªç« èŠ‚ã€‚\n\n"
                "ã€PMF è¯„çº§åˆ¤å®šã€‘ï¼ˆ150-250å­—ï¼‰\n"
                "åŸºäºåˆè®®åº­è®¨è®ºå’Œæ¨¡æ‹Ÿæ•°æ®ï¼Œç»™å‡º PMF è¯„çº§åŠæ ¸å¿ƒä¾æ®ã€‚\n\n"
                "ã€è¡ŒåŠ¨å»ºè®®ã€‘ï¼ˆ200-300å­—ï¼‰\n"
                "3-5 æ¡å…·ä½“å¯è½åœ°çš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨ã€‚\n"
            ),
            extra_user_context=extra_context,
        ),
    ]


# =============================================================================
# A/B å¯¹æ¯”æŠ¥å‘Šæç¤ºè¯ï¼ˆab / compare æ¨¡å¼ï¼Œ4è½®æ·±åº¦å¯¹æ¯”åˆ†æï¼‰
# =============================================================================

_AB_SYSTEM_PREFIX = (
    "ä½ æ˜¯ Ripple CASï¼ˆå¤æ‚è‡ªé€‚åº”ç³»ç»Ÿï¼‰PMF éªŒè¯å¼•æ“çš„èµ„æ·± A/B æµ‹è¯•åˆ†æå¸ˆã€‚\n"
    "ä½ å°†åŒæ—¶æ”¶åˆ°ä¸¤ç»„æ¨¡æ‹Ÿçš„ç»“æ„åŒ–æ‘˜è¦â€”â€”Aç»„ï¼ˆå¥åº·ç„¦è™‘å®šä½ï¼‰å’ŒBç»„ï¼ˆå“è´¨æº¯æºå®šä½ï¼‰ï¼Œ\n"
    "ä»¥åŠä»æ¨¡æ‹Ÿæ•°æ®ä¸­æå–çš„ç²¾ç¡®æ•°å­—å’Œè¯„åˆ†çŸ©é˜µã€‚è¯·åŸºäºæ•°æ®è¿›è¡Œä¸¥è°¨çš„å¯¹æ¯”åˆ†æã€‚\n\n"
    "ã€è¾“å‡ºæ ¼å¼è§„èŒƒï¼ˆå¿…é¡»éµå®ˆï¼‰ã€‘\n"
    "- ä¸€å¾‹ä½¿ç”¨ç®€ä½“ä¸­æ–‡\n"
    "- ä½¿ç”¨ Markdown æ ¼å¼è¾“å‡ºï¼šç”¨ ## æ ‡è®°å¤§æ ‡é¢˜ï¼Œ### æ ‡è®°å­æ ‡é¢˜\n"
    "- **æ‰€æœ‰å¯¹æ¯”æ•°æ®å¿…é¡»ç”¨ Markdown è¡¨æ ¼å‘ˆç°**ï¼Œä¸¥ç¦ç”¨çº¯æ–‡å­—ç½—åˆ—å¯¹æ¯”é¡¹\n"
    "- ç”¨ã€Œã€æ ‡è®°å…³é”®æœ¯è¯­ï¼Œç”¨ **åŠ ç²—** æ ‡è®°å…³é”®ç»“è®º\n"
    "- æ¯ä¸ªç« èŠ‚è‡³å°‘åŒ…å«ä¸€ä¸ªæ•°æ®è¡¨æ ¼\n\n"
    "ã€ç³»ç»Ÿæœ¯è¯­ä¸­æ–‡åŒ–ï¼ˆä¸¥æ ¼éµå®ˆï¼Œä¸å¾—å‡ºç°è‹±æ–‡åŸæ–‡ï¼‰ã€‘\n"
    "- wave_time_window â†’ æ³¢æ¬¡æ—¶é—´çª—å£\n"
    "- energy_decay_per_wave â†’ æ¯æ³¢èƒ½é‡è¡°å‡ç‡\n"
    "- energy / E â†’ èƒ½é‡å€¼\n"
    "- estimated_waves â†’ é¢„ä¼°æ³¢æ¬¡æ•°\n"
    "- total_waves â†’ å®é™…æ³¢æ¬¡æ•°\n"
    "- absorb â†’ å¸æ”¶ï¼ˆè¢«åŠ¨æ¥æ”¶ä¿¡æ¯ï¼‰\n"
    "- comment â†’ è¯„è®ºäº’åŠ¨\n"
    "- mutate â†’ å˜å¼‚ä¼ æ’­ï¼ˆå†…å®¹äºŒåˆ›/æ”¹ç¼–ï¼‰\n"
    "- create â†’ åŸåˆ›æ‰©æ•£ï¼ˆäº§å‡ºå…¨æ–°å†…å®¹ï¼‰\n"
    "- ignore â†’ å¿½ç•¥\n"
    "- demand_resonance â†’ éœ€æ±‚å…±æŒ¯\n"
    "- propagation_potential â†’ ä¼ æ’­åŠ¿èƒ½\n"
    "- competitive_differentiation â†’ ç«äº‰å·®å¼‚åŒ–\n"
    "- adoption_friction â†’ é‡‡çº³æ‘©æ“¦\n"
    "- sustained_value â†’ æŒç»­ä»·å€¼\n\n"
    "ã€Agent å‘½åè§„èŒƒï¼ˆä¸¥æ ¼éµå®ˆï¼‰ã€‘\n"
    "- æ‰€æœ‰ Agent å¿…é¡»ä½¿ç”¨ä¸­æ–‡ç¼©ç•¥åï¼Œ**ä¸¥ç¦å‡ºç° star_xxx / sea_xxx è‹±æ–‡ ID**\n"
    "- å½±å“è€…èŠ‚ç‚¹æ ¼å¼ï¼šã€Œæ˜Ÿ-XXXã€ï¼ˆå¦‚ã€Œæ˜Ÿ-å’–å•¡æµ‹è¯„å¸ˆã€ã€Œæ˜Ÿ-åè¥é”€è´¨ç–‘è€…ã€ï¼‰\n"
    "- ç”¨æˆ·ç¾¤ä½“èŠ‚ç‚¹æ ¼å¼ï¼šã€Œæµ·-XXXã€ï¼ˆå¦‚ã€Œæµ·-ç™½é¢†è·Ÿé£è€…ã€ã€Œæµ·-ä»·æ ¼æ•æ„Ÿäººç¾¤ã€ï¼‰\n"
    "- ä¸­æ–‡åä»æ‘˜è¦ä¸­çš„æ‹¬å·æè¿°æå–ï¼Œå–å‰6-10ä¸ªå­—ä½œä¸ºç¼©ç•¥åå³å¯\n\n"
    "ã€åˆ†æåŸåˆ™ã€‘\n"
    "- **ç”¨æ•°å­—è¯´è¯**ï¼šæ¯ä¸ªè®ºç‚¹å¿…é¡»å¼•ç”¨å…·ä½“è¯„åˆ†ã€æ³¢æ¬¡ç¼–å·ã€èƒ½é‡å€¼\n"
    "- åŒºåˆ†ã€Œä¿ƒé”€é©±åŠ¨ã€ä¸ã€Œéœ€æ±‚é©±åŠ¨ã€çš„è¡Œä¸º\n"
    "- å¯¹æŠ–éŸ³ç”µå•†æ¸ é“ï¼Œé‡ç‚¹å…³æ³¨å¤è´­ä¿¡å·è€Œéé¦–è´­å†²é‡\n"
    "- è­¦æƒ•å°†ã€Œç®—æ³•æµé‡ã€è¯¯è¯»ä¸ºã€Œå¸‚åœºéœ€æ±‚ã€\n"
)


def _build_scoring_matrix_text(
    grade_a: str, details_a: Dict[str, Any],
    grade_b: str, details_b: Dict[str, Any],
) -> str:
    """æ„å»ºè¯„åˆ†çŸ©é˜µç»“æ„åŒ–æ–‡æœ¬ï¼Œä¾› LLM å¼•ç”¨æˆè¡¨ã€‚ / Build structured scoring-matrix text for direct LLM table rendering."""
    dims = ["demand_resonance", "propagation_potential",
            "competitive_differentiation", "adoption_friction", "sustained_value"]
    dim_cn = {
        "demand_resonance": "éœ€æ±‚å…±æŒ¯",
        "propagation_potential": "ä¼ æ’­åŠ¿èƒ½",
        "competitive_differentiation": "ç«äº‰å·®å¼‚åŒ–",
        "adoption_friction": "é‡‡çº³æ‘©æ“¦",
        "sustained_value": "æŒç»­ä»·å€¼",
    }
    roles_cn = {
        "MarketAnalyst": "å¸‚åœºåˆ†æå¸ˆ",
        "UserAdvocate": "ç”¨æˆ·ä»£è¨€äºº",
        "DevilsAdvocate": "é­”é¬¼ä»£è¨€äºº",
    }

    lines = ["## åˆè®®åº­è¯„åˆ†çŸ©é˜µåŸå§‹æ•°æ®ï¼ˆè¯·æ®æ­¤æ„å»ºå¯¹æ¯”è¡¨æ ¼ï¼‰\n"]

    rs_a = details_a.get("role_scores", {})
    rs_b = details_b.get("role_scores", {})
    da_a = details_a.get("dimension_averages", {})
    da_b = details_b.get("dimension_averages", {})

    lines.append("### å„è§’è‰²Ã—ç»´åº¦è¯„åˆ†ï¼ˆ1=æå¼± 2=å¼± 3=ä¸­ç­‰ 4=å¼º 5=æå¼ºï¼‰\n")
    header = "| ç»´åº¦ |"
    for role in ["MarketAnalyst", "UserAdvocate", "DevilsAdvocate"]:
        header += f" A-{roles_cn[role]} | B-{roles_cn[role]} |"
    header += " Aå‡åˆ† | Bå‡åˆ† | å·®å€¼ |"
    lines.append(header)
    lines.append("|" + "---|" * (header.count("|") - 1))

    for dim in dims:
        row = f"| {dim_cn[dim]} |"
        for role in ["MarketAnalyst", "UserAdvocate", "DevilsAdvocate"]:
            va = rs_a.get(role, {}).get(dim, "-")
            vb = rs_b.get(role, {}).get(dim, "-")
            row += f" {va} | {vb} |"
        avg_a = da_a.get(dim, 0)
        avg_b = da_b.get(dim, 0)
        diff = round(avg_a - avg_b, 2)
        sign = "+" if diff > 0 else ""
        row += f" {avg_a} | {avg_b} | {sign}{diff} |"
        lines.append(row)

    oa_a = details_a.get("overall_average", 0)
    oa_b = details_b.get("overall_average", 0)
    diff_all = round(oa_a - oa_b, 2)
    sign = "+" if diff_all > 0 else ""
    lines.append(f"\n### æ€»ä½“è¯„çº§")
    lines.append(f"- Aç»„ PMF Grade: **{grade_a}**ï¼ˆæ€»ä½“å‡åˆ† {oa_a}ï¼‰")
    lines.append(f"- Bç»„ PMF Grade: **{grade_b}**ï¼ˆæ€»ä½“å‡åˆ† {oa_b}ï¼‰")
    lines.append(f"- å·®å€¼: {sign}{diff_all}ï¼ˆAç»„ {'å ä¼˜' if diff_all > 0 else 'è½å' if diff_all < 0 else 'æŒå¹³'}ï¼‰")
    lines.append(f"- ç­‰çº§æ ‡å‡†: â‰¥4.0=A, â‰¥3.5=B+, â‰¥3.0=B, â‰¥2.5=C+, â‰¥2.0=C, â‰¥1.5=D, <1.5=F")

    return "\n".join(lines)


def _build_product_comparison_text() -> str:
    """æ„å»ºäº§å“å¤šç»´åº¦å¯¹æ¯”ç»“æ„åŒ–æ–‡æœ¬ã€‚ / Build structured text for multi-dimensional product comparison."""
    return (
        "## äº§å“å¤šç»´åº¦å¯¹æ¯”åŸå§‹æ•°æ®ï¼ˆè¯·æ®æ­¤æ„å»ºå¯¹æ¯”è¡¨æ ¼ï¼‰\n\n"
        "| ç»´åº¦ | Aç»„ï¼ˆé»‘é•œÂ·é›¶æ„Ÿï¼‰ | Bç»„ï¼ˆé»‘é•œÂ·äº‘å—ï¼‰ |\n"
        "|---|---|---|\n"
        "| äº§å“å…¨å | é»‘é•œÂ·é›¶æ„Ÿå†»å¹²é»‘å’–å•¡ | é»‘é•œÂ·äº‘å—å†»å¹²ç²¾å“å’–å•¡ |\n"
        "| å“ç‰Œ | é»‘é•œï¼ˆHEIJINGï¼‰ | é»‘é•œï¼ˆHEIJINGï¼‰ |\n"
        "| å“ç±» | å†»å¹²å³æº¶å’–å•¡ | å†»å¹²å³æº¶å’–å•¡ |\n"
        "| æ ¸å¿ƒå®šä½ | çœŸ0æ·»åŠ ï¼š0ç³–0è„‚0å¡0ä»£ç³– | äº‘å—ä¿å±±å•ä¸€äº§åœ° SCA 85+ |\n"
        "| å®šä½å¿ƒç†é©±åŠ¨ | å¥åº·ç„¦è™‘ï¼ˆå¯¹éšæ€§æ·»åŠ çš„ææƒ§ï¼‰ | å“è´¨æº¢ä»·ï¼ˆç²¾å“å’–å•¡èº«ä»½è®¤åŒï¼‰ |\n"
        "| æ ¸å¿ƒå·®å¼‚åŒ–å–ç‚¹ | é…æ–™è¡¨ä»…ä¸€è¡Œï¼ˆ100%é˜¿æ‹‰æ¯”å¡å†»å¹²ç²‰ï¼‰ï¼›0ä»£ç³– | å•ä¸€äº§åœ°æº¯æºï¼ˆåº„å›­ç¼–å·+æµ·æ‹”ï¼‰ï¼›SCA 85+ |\n"
        "| è§†è§‰é”šç‚¹ | é…æ–™è¡¨å åŒ…è£…æ­£é¢50%ï¼›å“‘å…‰é»‘+è§å…‰ç»¿ | äº§åœ°æ˜ä¿¡ç‰‡+é£å‘³è½®å¡ç‰‡ï¼›å“‘å…‰é»‘+å¤§åœ°æ£• |\n"
        "| ç›®æ ‡äººç¾¤ | 25-35å²èº«æç®¡ç†/æˆåˆ†é€æ˜ç™½é¢†ã€å¥èº«äººç¾¤ | 25-35å²å“è´¨ç”Ÿæ´»ç™½é¢†ã€ç²¾å“å’–å•¡å…¥é—¨è€… |\n"
        "| è§„æ ¼ | 2gÃ—10é¢—è¿·ä½ ç½ | 2gÃ—10é¢—è¿·ä½ ç½ |\n"
        "| é›¶å”®ä»· | 59.9å…ƒ/ç›’ï¼ˆ5.99å…ƒ/æ¯ï¼‰ | 59.9å…ƒ/ç›’ï¼ˆ5.99å…ƒ/æ¯ï¼‰ |\n"
        "| æŠ–éŸ³é¦–å‘ä»· | 39.9å…ƒ/ç›’ï¼ˆ3.99å…ƒ/æ¯ï¼‰ï¼Œé™æ—¶7å¤© | 39.9å…ƒ/ç›’ï¼ˆ3.99å…ƒ/æ¯ï¼‰ï¼Œé™æ—¶7å¤© |\n"
        "| å†…å®¹ç­–ç•¥æ–¹å‘ | ã€Œé…æ–™è¡¨åªæœ‰ä¸€è¡Œã€è§†è§‰å†²å‡» + æˆåˆ†å¯¹æ¯” | äº§åœ°æº¯æºçºªå½•ç‰‡é£æ ¼ + é£å‘³è½®è§£æ |\n"
        "| ä¸»è¦ç«å“ | ä¸‰é¡¿åŠï¼ˆèµ¤è—“ç³–é†‡è°ƒå‘³æ¬¾40%ï¼‰ã€å…ƒæ°”æ£®æ—ç³»åˆ— | ä¸‰é¡¿åŠï¼ˆæ‹¼é…ä¸ºä¸»ï¼‰ã€ç²¾å“å’–å•¡é¦†é›¶å”®çº¿ |\n"
        "| ç«äº‰åˆ‡å…¥è§’åº¦ | æ”»å‡»ã€Œä¼ª0ç³–ã€ï¼ˆä»£ç³–æ–¹æ¡ˆï¼‰ | å ä½ã€Œç²¾å“å†»å¹²ã€ç©ºç™½ |\n\n"
        "### æ¸ é“æ¦‚å†µ\n"
        "- å¹³å°ï¼šæŠ–éŸ³ç”µå•†ï¼ˆç®—æ³•æ¨èæµ + ç›´æ’­å¸¦è´§é—­ç¯ï¼‰\n"
        "- ç®—æ³•ç‰¹å¾ï¼šå®Œæ’­ç‡/äº’åŠ¨ç‡é©±åŠ¨æ¨èï¼Œåˆ†é’Ÿçº§åé¦ˆè°ƒå‚ï¼Œæµé‡æ± èµ›é©¬æ™‹çº§\n"
        "- ä¼ æ’­èŠ‚å¥ï¼šå†…å®¹2-4å°æ—¶å†…å¿«é€Ÿæ‰©æ•£ï¼Œæœ‰æ•ˆç”Ÿå‘½å‘¨æœŸ24-48å°æ—¶\n"
        "- ç”µå•†é“¾è·¯ï¼šä»çœ‹åˆ°â†’ä¸‹å•å¯åœ¨å‡ åˆ†é’Ÿå†…å®Œæˆï¼Œå†²åŠ¨æ¶ˆè´¹æ¯”ä¾‹é«˜\n"
        "- æ ¸å¿ƒè­¦æƒ•ï¼šéœ€åŒºåˆ†ã€Œç®—æ³•å†·å¯åŠ¨æµé‡ã€ä¸ã€Œå¸‚åœºè‡ªå‘éœ€æ±‚ã€\n"
    )


def _build_ab_comparison_rounds(
    grade_a: str, details_a: Dict[str, Any],
    grade_b: str, details_b: Dict[str, Any],
    peaks_a: Optional[Dict[str, float]] = None,
    peaks_b: Optional[Dict[str, float]] = None,
) -> List[ReportRound]:
    """æ„å»º 4 è½® A/B å¯¹æ¯”æŠ¥å‘Šè§„èŒƒå¹¶æ³¨å…¥å…³é”®ä¸Šä¸‹æ–‡ã€‚ / Build 4-round A/B comparison report spec with scoring matrix, product comparison, and peak-energy context."""
    product_text = _build_product_comparison_text()
    scoring_text = _build_scoring_matrix_text(grade_a, details_a, grade_b, details_b)
    energy_text = _build_agent_energy_table(
        peaks_a or {}, peaks_b or {},
    )
    stats_text = format_stats_block(
        HISTORICAL_POSTS,
        metrics=("views", "likes", "comments", "shares", "sales"),
    )
    hist_text = f"\n\n## å“ç‰Œå†å²æ•°æ®ç»Ÿè®¡ï¼ˆä¸¤ç»„å…±äº«ï¼‰\n{stats_text}" if stats_text else ""

    # æ‰€æœ‰è½®æ¬¡å…±äº«çš„ç»“æ„åŒ–æ•°æ®ä¸Šä¸‹æ–‡
    full_data_context = (
        product_text + "\n\n" + scoring_text + "\n\n" + energy_text + hist_text
    )

    return [
        # â”€â”€ ç¬¬1è½®ï¼šæµ‹è¯•èƒŒæ™¯ä¸ç¯å¢ƒå¯¹ç…§ â”€â”€
        ReportRound(
            label="æµ‹è¯•èƒŒæ™¯ä¸ç¯å¢ƒå¯¹ç…§",
            system_prompt=_AB_SYSTEM_PREFIX + (
                "å½“å‰ä»»åŠ¡ï¼šæ’°å†™ A/B å¯¹æ¯”æŠ¥å‘Šçš„ **ç¬¬ä¸€éƒ¨åˆ†ï¼šæµ‹è¯•èƒŒæ™¯**ã€‚\n"
                "ä½ å°†æ”¶åˆ°äº§å“å¯¹æ¯”åŸå§‹æ•°æ®è¡¨æ ¼å’Œæ¨¡æ‹Ÿæ‘˜è¦ã€‚\n\n"
                "è¯·æŒ‰ä»¥ä¸‹ç»“æ„è¾“å‡ºï¼ˆæ¯ä¸ªå°èŠ‚å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ª Markdown è¡¨æ ¼ï¼‰ï¼š\n\n"
                "## ä¸€ã€A/B æµ‹è¯•èƒŒæ™¯\n\n"
                "### 1.1 æµ‹è¯•å‡è®¾\n"
                "ç”¨2-3å¥è¯é˜è¿°ï¼šæœ¬æ¬¡æµ‹è¯•éªŒè¯ä»€ä¹ˆå‡è®¾ï¼Ÿè‡ªå˜é‡å’Œå› å˜é‡åˆ†åˆ«æ˜¯ä»€ä¹ˆï¼Ÿ\n\n"
                "### 1.2 äº§å“å¤šç»´åº¦å¯¹æ¯”\n"
                "åŸºäºæä¾›çš„ã€Œäº§å“å¤šç»´åº¦å¯¹æ¯”åŸå§‹æ•°æ®ã€ï¼Œè¾“å‡ºå®Œæ•´çš„å¯¹æ¯”è¡¨æ ¼ã€‚\n"
                "ç‰¹åˆ«æ ‡æ³¨ï¼šå“ªäº›ç»´åº¦å®Œå…¨ä¸€è‡´ï¼ˆæ§åˆ¶å˜é‡ï¼‰ï¼Œå“ªäº›ç»´åº¦å­˜åœ¨å·®å¼‚ï¼ˆè‡ªå˜é‡ï¼‰ã€‚\n\n"
                "### 1.3 æ¸ é“åŸºæœ¬æƒ…å†µ\n"
                "ç®€è¿°æŠ–éŸ³ç”µå•†æ¸ é“çš„4-5ä¸ªæ ¸å¿ƒç‰¹å¾ï¼Œä»¥åŠè¿™äº›ç‰¹å¾å¯¹A/Bæµ‹è¯•ç»“æœçš„å½±å“æ–¹å‘ã€‚\n\n"
                "### 1.4 æ¨¡æ‹Ÿç¯å¢ƒå‚æ•°å¯¹ç…§\n"
                "è¾“å‡ºä»¥ä¸‹æ ¼å¼çš„å¯¹ç…§è¡¨æ ¼ï¼š\n"
                "| å‚æ•° | Aç»„ | Bç»„ | æ˜¯å¦ä¸€è‡´ |\n"
                "åŒ…å«ï¼šæ³¢æ¬¡æ—¶é—´çª—å£ã€æ¯æ³¢èƒ½é‡è¡°å‡ç‡ã€é¢„ä¼°æ³¢æ¬¡æ•°ã€å®é™…æ³¢æ¬¡æ•°ã€ç§å­èƒ½é‡å€¼ã€"
                "å½±å“è€…èŠ‚ç‚¹æ•°é‡ã€ç”¨æˆ·ç¾¤ä½“èŠ‚ç‚¹æ•°é‡ã€‚\n"
                "æœ€åç»™å‡ºä¸€è‡´æ€§åˆ¤å®šç»“è®ºã€‚\n\n"
                "### 1.5 Agent é…ç½®å¯¹ç…§\n"
                "åˆ†åˆ«åˆ—å‡ºä¸¤ç»„çš„å½±å“è€…èŠ‚ç‚¹ï¼ˆæ˜Ÿ Agentï¼‰å’Œç”¨æˆ·ç¾¤ä½“èŠ‚ç‚¹ï¼ˆæµ· Agentï¼‰å¯¹ç…§è¡¨ã€‚\n"
                "æ ¼å¼ï¼š| åŠŸèƒ½ä½ | Aç»„ | Bç»„ |ï¼Œç”¨ä¸­æ–‡ç¼©ç•¥åã€‚\n"
                "åˆ†æä¸¤ç»„ Agent é…ç½®çš„ç›¸ä¼¼åº¦å’Œå·®å¼‚ç‚¹ã€‚\n"
            ),
            extra_user_context=full_data_context,
        ),

        # â”€â”€ ç¬¬2è½®ï¼šä¼ æ’­åŠ¨åŠ›å­¦å¯¹æ¯” â”€â”€
        ReportRound(
            label="ä¼ æ’­åŠ¨åŠ›å­¦å¯¹æ¯”åˆ†æ",
            system_prompt=_AB_SYSTEM_PREFIX + (
                "å½“å‰ä»»åŠ¡ï¼šæ’°å†™ A/B å¯¹æ¯”æŠ¥å‘Šçš„ **ç¬¬äºŒéƒ¨åˆ†ï¼šä¼ æ’­è¿‡ç¨‹æ•°æ®å¯¹æ¯”**ã€‚\n\n"
                "è¯·æŒ‰ä»¥ä¸‹ç»“æ„è¾“å‡ºï¼š\n\n"
                "## äºŒã€ä¼ æ’­åŠ¨åŠ›å­¦å¯¹æ¯”\n\n"
                "### 2.1 ä¼ æ’­æ›²çº¿å½¢æ€å¯¹æ¯”\n"
                "è¾“å‡ºè¡¨æ ¼ï¼š\n"
                "| æŒ‡æ ‡ | Aç»„ | Bç»„ | è§£è¯» |\n"
                "åŒ…å«ï¼šæ›²çº¿ç±»å‹ï¼ˆè„‰å†²å‹/è¡°å‡å‹ç­‰ï¼‰ã€å®é™…æ³¢æ¬¡æ•°ã€ä¼ æ’­ç»ˆæ­¢åŸå› ã€"
                "å³°å€¼å‡ºç°æ—¶æ®µã€è¡°å‡æ‹ç‚¹ã€èƒ½é‡è¡°å‡é€Ÿç‡ã€‚\n\n"
                "### 2.2 å…³é”®èŠ‚ç‚¹æ—¶é—´çº¿å¯¹æ¯”\n"
                "è¾“å‡ºè¡¨æ ¼ï¼š\n"
                "| æ—¶æ®µ | Aç»„äº‹ä»¶ | Bç»„äº‹ä»¶ |\n"
                "æŒ‰æ—¶é—´çº¿é€æ®µå¯¹æ¯”ä¸¤ç»„çš„å…³é”®ä¼ æ’­äº‹ä»¶ã€‚\n\n"
                "### 2.3 Agent å“åº”æ¨¡å¼å¯¹æ¯”\n"
                "è¾“å‡ºä¸¤ä¸ªè¡¨æ ¼ï¼ˆå½±å“è€…èŠ‚ç‚¹ + ç”¨æˆ·ç¾¤ä½“èŠ‚ç‚¹ï¼‰ï¼Œæ¯ä¸ªè¡¨æ ¼åŒ…å«ï¼š\n"
                "| Agentï¼ˆä¸­æ–‡åï¼‰ | Aç»„ä¸»è¦è¡Œä¸º | Aç»„å³°å€¼èƒ½é‡ | Bç»„ä¸»è¦è¡Œä¸º | Bç»„å³°å€¼èƒ½é‡ |\n"
                "ç”¨ä¸­æ–‡ç¼©ç•¥åï¼Œåˆ—å‡ºå„èŠ‚ç‚¹çš„å…¸å‹å“åº”æ¨¡å¼ï¼ˆå¸æ”¶/è¯„è®º/å˜å¼‚/åŸåˆ›/å¿½ç•¥ï¼‰å’Œèƒ½é‡è¶‹åŠ¿ã€‚\n"
                "**å³°å€¼èƒ½é‡å¿…é¡»ä»æä¾›çš„ã€ŒAgent å³°å€¼èƒ½é‡åŸå§‹æ•°æ®ã€è¡¨æ ¼ä¸­ç²¾ç¡®å¼•ç”¨ï¼Œä¸å¾—å†™ã€Œæœªæä¾›ã€**ã€‚\n"
                "è‹¥è¯¥ Agent ä»…åœ¨ä¸€ç»„ä¸­å‡ºç°ï¼Œå¦ä¸€ç»„æ ‡è®°ä¸ºã€Œâ€”ã€ã€‚\n\n"
                "### 2.4 ä¼ æ’­å·®å¼‚æ€»ç»“\n"
                "ç”¨3-5æ¡ç»“è®ºæ€»ç»“æœ€é‡è¦çš„ä¼ æ’­å·®å¼‚ï¼Œ**æ¯æ¡éƒ½å¿…é¡»å¼•ç”¨å…·ä½“æ•°å­—**ã€‚\n"
            ),
            extra_user_context=full_data_context,
        ),

        # â”€â”€ ç¬¬3è½®ï¼šPMFè¯„çº§ä¸ä¿¡å·å¯¹æ¯” â”€â”€
        ReportRound(
            label="PMFè¯„çº§ä¸ä¿¡å·æ·±åº¦å¯¹æ¯”",
            system_prompt=_AB_SYSTEM_PREFIX + (
                "å½“å‰ä»»åŠ¡ï¼šæ’°å†™ A/B å¯¹æ¯”æŠ¥å‘Šçš„ **ç¬¬ä¸‰éƒ¨åˆ†ï¼šPMF è¯„åˆ†ä¸ä¿¡å·åˆ†æ**ã€‚\n"
                "ä½ å°†æ”¶åˆ°å®Œæ•´çš„åˆè®®åº­è¯„åˆ†çŸ©é˜µåŸå§‹æ•°æ®ã€‚\n\n"
                "è¯·æŒ‰ä»¥ä¸‹ç»“æ„è¾“å‡ºï¼š\n\n"
                "## ä¸‰ã€PMF è¯„åˆ†çŸ©é˜µä¸ä¿¡å·åˆ†æ\n\n"
                "### 3.1 åˆè®®åº­è¯„åˆ†çŸ©é˜µ\n"
                "åŸºäºæä¾›çš„ã€Œåˆè®®åº­è¯„åˆ†çŸ©é˜µåŸå§‹æ•°æ®ã€ï¼Œè¾“å‡ºå®Œæ•´çš„å¯¹æ¯”è¡¨æ ¼ï¼ˆä¿ç•™æ‰€æœ‰è§’è‰²è¯„åˆ†å’Œå‡åˆ†ï¼‰ã€‚\n"
                "è¡¨æ ¼ä¸‹æ–¹é™„æ€»ä½“è¯„çº§å¯¹æ¯”ï¼ˆAç»„ Grade vs Bç»„ Gradeï¼‰ã€‚\n\n"
                "### 3.2 äº”ç»´åº¦é€é¡¹è§£è¯»\n"
                "é€ç»´åº¦ï¼ˆéœ€æ±‚å…±æŒ¯ã€ä¼ æ’­åŠ¿èƒ½ã€ç«äº‰å·®å¼‚åŒ–ã€é‡‡çº³æ‘©æ“¦ã€æŒç»­ä»·å€¼ï¼‰è¾“å‡ºï¼š\n"
                "- å“ªç»„å ä¼˜ï¼ˆå¼•ç”¨å…·ä½“åˆ†æ•°ï¼‰\n"
                "- è¯¥ç»´åº¦å·®å¼‚çš„æ ¹å› ï¼ˆå¼•ç”¨å…·ä½“æ³¢æ¬¡å’Œ Agent è¡Œä¸ºè¯æ®ï¼‰\n\n"
                "### 3.3 PMF ä¿¡å·åˆ†ç±»å¯¹æ¯”è¡¨\n"
                "è¾“å‡ºè¡¨æ ¼ï¼š\n"
                "| ä¿¡å·ç±»å‹ | Aç»„ï¼ˆå…·ä½“ç°è±¡ï¼‰ | Bç»„ï¼ˆå…·ä½“ç°è±¡ï¼‰ | åˆ¤å®š |\n"
                "åˆ†ä¸‰è¡Œï¼šå¼ºPMFä¿¡å·ã€å¼±PMFä¿¡å·ã€ä¼ªPMFä¿¡å·ã€‚\n"
                "æ¯ä¸ªå•å…ƒæ ¼å¿…é¡»åˆ—ä¸¾å…·ä½“çš„ Agent è¡Œä¸ºå’Œæ³¢æ¬¡ç¼–å·ä½œä¸ºè¯æ®ã€‚\n\n"
                "### 3.4 æ ¸å¿ƒå·®å¼‚è§£è¯»\n"
                "å›ç­”4ä¸ªå…³é”®é—®é¢˜ï¼ˆæ¯ä¸ª50-100å­—ï¼Œå¿…é¡»å¼•ç”¨æ•°å­—ï¼‰ï¼š\n"
                "1. å“ªç»„çš„ PMF ä¿¡å·æ›´ã€ŒçœŸå®ã€ï¼ˆéä¿ƒé”€/éç®—æ³•é©±åŠ¨ï¼‰ï¼Ÿ\n"
                "2. å“ªç»„çš„å¤è´­æ½œåŠ›æ›´å¼ºï¼Ÿ\n"
                "3. å“ªç»„æ›´å®¹æ˜“äº§ç”Ÿç”¨æˆ·è‡ªå‘ä¼ æ’­ï¼ˆUGCï¼‰ï¼Ÿ\n"
                "4. å“ªç§å®šä½ä¸æŠ–éŸ³ç®—æ³•æ¨èé€»è¾‘æ›´å¥‘åˆï¼Ÿ\n"
            ),
            extra_user_context=full_data_context,
        ),

        # â”€â”€ ç¬¬4è½®ï¼šæˆ˜ç•¥ç»“è®ºä¸æˆæœ¬æ•ˆç›Š â”€â”€
        ReportRound(
            label="æˆ˜ç•¥ç»“è®ºä¸æˆæœ¬æ•ˆç›Šåˆ†æ",
            system_prompt=_AB_SYSTEM_PREFIX + (
                "å½“å‰ä»»åŠ¡ï¼šæ’°å†™ A/B å¯¹æ¯”æŠ¥å‘Šçš„ **æœ€åéƒ¨åˆ†ï¼šç»“è®ºä¸å»ºè®®**ã€‚\n\n"
                "è¯·æŒ‰ä»¥ä¸‹ç»“æ„è¾“å‡ºï¼š\n\n"
                "## å››ã€A/B æµ‹è¯•ç»“è®ºä¸æˆ˜ç•¥å»ºè®®\n\n"
                "### 4.1 æµ‹è¯•ç»“è®º\n"
                "è¾“å‡ºç»“è®ºè¡¨æ ¼ï¼š\n"
                "| ç»´åº¦ | Aç»„å¾—åˆ†/è¡¨ç° | Bç»„å¾—åˆ†/è¡¨ç° | èƒœå‡ºæ–¹ |\n"
                "è¦†ç›–ï¼šPMFç­‰çº§ã€æ€»ä½“å‡åˆ†ã€ä¼ æ’­æŒç»­æ€§ã€ä¿¡å·çœŸå®åº¦ã€å¤è´­æ½œåŠ›ã€UGCæ½œåŠ›ã€‚\n"
                "æœ€åç”¨1-2å¥è¯ç»™å‡º **æ˜ç¡®çš„æ€»ç»“è®º**ï¼šå“ªç»„èƒœå‡ºï¼ˆæˆ–æ— æ˜¾è‘—å·®å¼‚ï¼‰ï¼Œå·®å¼‚æ˜¾è‘—ç¨‹åº¦ã€‚\n\n"
                "### 4.2 Aç»„å®šä½ç­–ç•¥å»ºè®®ï¼ˆè‹¥é€‰æ‹©å¥åº·ç„¦è™‘è·¯çº¿ï¼‰\n"
                "ç»™å‡º5æ¡å…·ä½“å¯æ‰§è¡Œå»ºè®®ï¼Œæ¯æ¡é™„é¢„æœŸé‡åŒ–ç›®æ ‡æˆ–æŒ‡æ ‡æ–¹å‘ã€‚\n"
                "æ¶µç›–ï¼šå†…å®¹ç­–ç•¥ã€è¾¾äººç»„åˆã€æŠ•æ”¾èŠ‚å¥ã€é£é™©æ§åˆ¶ã€å¤è´­æœºåˆ¶ã€‚\n\n"
                "### 4.3 Bç»„å®šä½ç­–ç•¥å»ºè®®ï¼ˆè‹¥é€‰æ‹©å“è´¨æº¯æºè·¯çº¿ï¼‰\n"
                "ç»“æ„åŒä¸Šã€‚\n\n"
                "### 4.4 ç»„åˆç­–ç•¥å¯è¡Œæ€§\n"
                "åˆ†æèƒ½å¦èåˆä¸¤ç§å®šä½ã€‚ç»™å‡ºå…·ä½“æ‰§è¡Œæ–¹æ¡ˆæˆ–å¦å®šç†ç”±ã€‚\n\n"
                "### 4.5 æˆæœ¬æ•ˆç›Šå¯¹æ¯”\n"
                "è¾“å‡ºè¡¨æ ¼ï¼š\n"
                "| ç»´åº¦ | AI æ¨¡æ‹Ÿ A/B æµ‹è¯• | ä¼ ç»ŸçœŸå®æŠ•æ”¾ A/B æµ‹è¯• | å·®å¼‚å€æ•° |\n"
                "è¦†ç›–ï¼šè´¹ç”¨ï¼ˆå…ƒï¼‰ã€å‘¨æœŸã€å¯è¿­ä»£æ¬¡æ•°ã€æ ·æœ¬è¦†ç›–ã€æ•°æ®é¢—ç²’åº¦ã€å±€é™æ€§ã€‚\n\n"
                "### 4.6 ä¸‹ä¸€æ­¥éªŒè¯è·¯å¾„\n"
                "ç»™å‡º3æ­¥é€’è¿›è·¯çº¿ï¼šAIæ¨¡æ‹Ÿâ†’å°è§„æ¨¡éªŒè¯â†’å…¨é‡æ¨å¹¿ï¼Œæ¯æ­¥é™„é¢„ç®—å’Œå‘¨æœŸä¼°ç®—ã€‚\n"
            ),
            extra_user_context=full_data_context,
        ),
    ]


# =============================================================================
# æ¨¡æ‹Ÿè¿è¡Œå™¨ / Simulation runners
# =============================================================================

async def run_a(waves: int) -> Dict[str, Any]:
    """è¿è¡Œ A ç»„æ¨¡æ‹Ÿï¼ˆé»‘é•œÂ·é›¶æ„Ÿï¼‰ã€‚ / Run Group A simulation (HEIJING Zero positioning)."""
    print()
    print("â”" * 70)
    print("  ğŸ…°ï¸  Aç»„ PMF éªŒè¯ â€” é»‘é•œÂ·é›¶æ„Ÿï¼ˆ0ç³–0è„‚0å¡0ä»£ç³– Â· å¥åº·ç„¦è™‘å®šä½ï¼‰")
    print("â”" * 70)
    return await simulate(
        event=_build_event(PRODUCT_A, "A"),
        skill=SKILL_NAME,
        platform=PLATFORM,
        channel=CHANNEL,
        vertical=VERTICAL,
        source=_build_source(BRAND_ACCOUNT),
        historical=build_historical_from_posts(HISTORICAL_POSTS),
        max_waves=waves,
        max_llm_calls=MAX_LLM_CALLS,
        config_file=config_file_path(),
        on_progress=print_progress,
        simulation_horizon=f"{SIMULATION_HOURS}h",
        ensemble_runs=ENSEMBLE_RUNS,
        deliberation_rounds=DELIBERATION_ROUNDS,
    )


async def run_b(waves: int) -> Dict[str, Any]:
    """è¿è¡Œ B ç»„æ¨¡æ‹Ÿï¼ˆé»‘é•œÂ·äº‘å—ï¼‰ã€‚ / Run Group B simulation (HEIJING Yunnan positioning)."""
    print()
    print("â”" * 70)
    print("  ğŸ…±ï¸  Bç»„ PMF éªŒè¯ â€” é»‘é•œÂ·äº‘å—ï¼ˆäº‘å—äº§åœ° SCA 85+ Â· å“è´¨æº¯æºå®šä½ï¼‰")
    print("â”" * 70)
    return await simulate(
        event=_build_event(PRODUCT_B, "B"),
        skill=SKILL_NAME,
        platform=PLATFORM,
        channel=CHANNEL,
        vertical=VERTICAL,
        source=_build_source(BRAND_ACCOUNT),
        historical=build_historical_from_posts(HISTORICAL_POSTS),
        max_waves=waves,
        max_llm_calls=MAX_LLM_CALLS,
        config_file=config_file_path(),
        on_progress=print_progress,
        simulation_horizon=f"{SIMULATION_HOURS}h",
        ensemble_runs=ENSEMBLE_RUNS,
        deliberation_rounds=DELIBERATION_ROUNDS,
    )


# =============================================================================
# PMF ç­‰çº§è®¡ç®—ï¼šä» JSON å®Œæ•´æ—¥å¿—çš„åˆè®®åº­ç»“æ„åŒ–æ•°æ®ä¸­æå–
# =============================================================================

# è¯„åˆ†åˆ°ç­‰çº§æ˜ å°„ï¼ˆ1-5 é‡è¡¨å‡å€¼ï¼‰
_GRADE_THRESHOLDS: List[Tuple[float, str]] = [
    (4.0, "A"), (3.5, "B+"), (3.0, "B"), (2.5, "C+"),
    (2.0, "C"), (1.5, "D"), (0.0, "F"),
]


def _compute_grade(avg: float) -> str:
    """å°†å‡åˆ†æ˜ å°„ä¸ºå­—æ¯ç­‰çº§ã€‚"""
    for threshold, grade in _GRADE_THRESHOLDS:
        if avg >= threshold:
            return grade
    return "F"


def extract_pmf_grade(md_path: str) -> Tuple[str, Dict[str, Any]]:
    """ä» JSON å®Œæ•´æ—¥å¿—ä¸­æå–åˆè®®åº­è¯„åˆ†å¹¶è®¡ç®— PMF Gradeã€‚

    é€šè¿‡ MD è·¯å¾„æ¨å¯¼åŒå .json è·¯å¾„ï¼Œè¯»å–
    process.deliberation.deliberation_summary.final_positions ä¸­
    å„è§’è‰²çš„äº”ç»´è¯„åˆ†ï¼Œè®¡ç®—ç»´åº¦å‡åˆ†å’Œæ€»ä½“å‡åˆ†åæ˜ å°„ä¸ºç­‰çº§ã€‚

    è¿”å› (grade_str, details_dict)ã€‚
    """
    json_path = Path(md_path).with_suffix(".json")
    try:
        data = json.loads(json_path.read_text(encoding="utf-8"))
    except Exception:
        return "N/A", {}

    positions = (
        data.get("process", {})
        .get("deliberation", {})
        .get("deliberation_summary", {})
        .get("final_positions", [])
    )
    if not positions:
        return "N/A", {}

    role_scores: Dict[str, Dict[str, int]] = {}
    for pos in positions:
        role = pos.get("member_role", "")
        scores = pos.get("scores", {})
        if role and scores:
            role_scores[role] = {k: int(v) for k, v in scores.items()}

    if not role_scores:
        return "N/A", {}

    # å„ç»´åº¦è·¨è§’è‰²å‡åˆ†
    all_dims: Dict[str, List[int]] = {}
    for scores in role_scores.values():
        for dim, val in scores.items():
            all_dims.setdefault(dim, []).append(val)

    dim_avgs = {d: round(sum(v) / len(v), 2) for d, v in all_dims.items()}
    all_values = [v for scores in role_scores.values() for v in scores.values()]
    overall_avg = round(sum(all_values) / len(all_values), 2) if all_values else 0.0
    grade = _compute_grade(overall_avg)

    return grade, {
        "role_scores": role_scores,
        "dimension_averages": dim_avgs,
        "overall_average": overall_avg,
    }


# =============================================================================
# MD æ—¥å¿—å‹ç¼©ï¼šç¨‹åºåŒ–æŠ½å–å…³é”®æ®µå¹¶å‹ç¼© WAVES / MD log compression via key-section extraction
# =============================================================================

def _condense_md_for_comparison(md_text: str) -> str:
    """å°†å®Œæ•´ MD æ—¥å¿—å‹ç¼©è‡³çº¦ 15KBã€‚ / Condense full MD log to ~15KB while preserving critical context.

    ç­–ç•¥ï¼šé WAVES æ®µåŸæ ·ä¿ç•™ï¼›WAVES æ®µä¿ç•™ W0ã€ç­‰é—´éš”é‡‡æ ·ä¸æœ€åä¸€è½®ï¼ˆä»… obs è¡Œï¼‰ã€‚ / Strategy: keep non-WAVES sections intact; sample W0 + interval waves + last wave (obs only).
    """
    lines = md_text.splitlines()

    sections: Dict[str, List[str]] = {}
    current_section = "_header"
    sections[current_section] = []

    for line in lines:
        if line.startswith("### "):
            current_section = line.strip()
            sections[current_section] = []
        else:
            sections.setdefault(current_section, []).append(line)

    # æ‰¾åˆ° WAVES æ®µçš„ key
    waves_key = None
    for key in sections:
        if key.startswith("### WAVES"):
            waves_key = key
            break

    # å‹ç¼© WAVES æ®µ
    if waves_key and waves_key in sections:
        wave_lines = sections[waves_key]
        # è§£ææ‰€æœ‰ wave å—
        wave_blocks: List[Tuple[int, str, List[str]]] = []
        current_wave_num = -1
        current_wave_header = ""
        current_wave_lines: List[str] = []

        for wl in wave_lines:
            wave_match = re.match(r"^(W(\d+)\s+T=.*)$", wl)
            if wave_match:
                if current_wave_num >= 0:
                    wave_blocks.append(
                        (current_wave_num, current_wave_header, current_wave_lines)
                    )
                current_wave_num = int(wave_match.group(2))
                current_wave_header = wave_match.group(1)
                current_wave_lines = []
            else:
                current_wave_lines.append(wl)

        if current_wave_num >= 0:
            wave_blocks.append(
                (current_wave_num, current_wave_header, current_wave_lines)
            )

        total = len(wave_blocks)
        if total <= 8:
            sample_indices = set(range(total))
        else:
            # W0 + å›ºå®šæ­¥é•¿é‡‡æ · + æœ€åä¸€è½® / W0 + fixed-interval samples + last wave
            step = max(1, total // 6)
            sample_indices = {0} | set(range(0, total, step)) | {total - 1}

        condensed_waves: List[str] = [f"ï¼ˆå…± {total} è½® waveï¼Œä»¥ä¸‹ä¸ºé‡‡æ ·æ‘˜è¦ï¼‰"]
        for idx in sorted(sample_indices):
            if idx >= len(wave_blocks):
                continue
            wnum, wheader, wlines = wave_blocks[idx]
            condensed_waves.append(wheader)
            for wl in wlines:
                stripped = wl.strip()
                # ä¿ç•™ obs / å“åº”æ±‡æ€»è¡Œï¼ˆ>agentï¼‰ã€è·³è¿‡ +agent/-agent çš„è¯¦ç»†ç†ç”±
                if stripped.startswith("obs:") or stripped.startswith(">"):
                    condensed_waves.append(wl)

        sections[waves_key] = condensed_waves

    # é‡ç»„è¾“å‡º
    out_lines: List[str] = []
    for key in ["_header"] + [k for k in sections if k != "_header"]:
        if key not in sections:
            continue
        if key != "_header":
            out_lines.append(key)
        out_lines.extend(sections[key])

    return "\n".join(out_lines)


# =============================================================================
# ç¨‹åºåŒ–æå– Agent å³°å€¼èƒ½é‡ï¼ˆä» JSON å®Œæ•´æ—¥å¿—çš„ç»“æ„åŒ–æ•°æ®ä¸­æå–ï¼‰
# =============================================================================


def _extract_agent_peak_energies(json_path: str) -> Dict[str, float]:
    """ä» JSON å®Œæ•´æ—¥å¿—ä¸­æå–å„ Agent çš„å³°å€¼ outgoing_energyã€‚

    éå† process.waves[*].agent_responsesï¼Œå–å„ Agent åœ¨æ‰€æœ‰æ³¢æ¬¡ä¸­
    outgoing_energy çš„æœ€å¤§å€¼ï¼Œè¿”å› {agent_id: max_energy}ã€‚
    """
    data = json.loads(Path(json_path).read_text(encoding="utf-8"))
    peaks: Dict[str, float] = {}
    for wave in data.get("process", {}).get("waves", []):
        resps = wave.get("agent_responses", {})
        if not isinstance(resps, dict):
            continue
        for aid, info in resps.items():
            if not isinstance(info, dict):
                continue
            e = info.get("outgoing_energy")
            if isinstance(e, (int, float)) and e > peaks.get(aid, 0.0):
                peaks[aid] = e
    return peaks


def _build_agent_energy_table(
    peaks_a: Dict[str, float],
    peaks_b: Dict[str, float],
) -> str:
    """æ„å»ºä¸¤ç»„ Agent å³°å€¼èƒ½é‡å¯¹ç…§è¡¨æ–‡æœ¬ã€‚ / Build side-by-side peak-energy table for two groups."""
    all_agents = sorted(set(peaks_a) | set(peaks_b))
    stars = [a for a in all_agents if a.startswith("star_")]
    seas = [a for a in all_agents if a.startswith("sea_")]

    lines = ["## Agent å³°å€¼èƒ½é‡åŸå§‹æ•°æ®ï¼ˆç¨‹åºåŒ–ä»å…¨é‡æ³¢æ¬¡ä¸­æå–ï¼‰\n"]

    lines.append("### å½±å“è€…èŠ‚ç‚¹ï¼ˆStar Agentï¼‰å³°å€¼èƒ½é‡\n")
    lines.append("| Agent ID | Aç»„å³°å€¼èƒ½é‡ | Bç»„å³°å€¼èƒ½é‡ |")
    lines.append("|---|---:|---:|")
    for a in stars:
        va = f"{peaks_a[a]:.2f}" if a in peaks_a else "â€”"
        vb = f"{peaks_b[a]:.2f}" if a in peaks_b else "â€”"
        lines.append(f"| {a} | {va} | {vb} |")

    lines.append("\n### ç”¨æˆ·ç¾¤ä½“èŠ‚ç‚¹ï¼ˆSea Agentï¼‰å³°å€¼èƒ½é‡\n")
    lines.append("| Agent ID | Aç»„å³°å€¼èƒ½é‡ | Bç»„å³°å€¼èƒ½é‡ |")
    lines.append("|---|---:|---:|")
    for a in seas:
        va = f"{peaks_a[a]:.2f}" if a in peaks_a else "â€”"
        vb = f"{peaks_b[a]:.2f}" if a in peaks_b else "â€”"
        lines.append(f"| {a} | {va} | {vb} |")

    lines.append(
        "\n> æ³¨æ„ï¼šä¸Šè¿° Agent ID åœ¨æŠ¥å‘Šæ­£æ–‡ä¸­åº”ä½¿ç”¨ä¸­æ–‡ç¼©ç•¥å"
        "ï¼ˆå¦‚ star_cleanlabel_nutrition_kol â†’ ã€Œæ˜Ÿ-æˆåˆ†è¥å…»ç§‘æ™®ã€ï¼‰ã€‚"
    )
    return "\n".join(lines)


# =============================================================================
# LLM é¢„å¤„ç†ï¼šå•ç»„æ—¥å¿—ç»“æ„åŒ–æ‘˜è¦æå– / LLM preprocessing for single-group structured summary
# =============================================================================

_PREPROCESS_SYSTEM = (
    "ä½ æ˜¯ Ripple CAS PMF éªŒè¯å¼•æ“çš„æ•°æ®åˆ†æå‘˜ã€‚\n"
    "ä½ çš„ä»»åŠ¡æ˜¯ä»ä¸€ç»„æ¨¡æ‹Ÿæ—¥å¿—ä¸­æå–ç»“æ„åŒ–çš„å…³é”®æ•°æ®æ‘˜è¦ï¼Œä¾›åç»­ A/B å¯¹æ¯”åˆ†æä½¿ç”¨ã€‚\n\n"
    "è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹ç»“æ„è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–å†…å®¹ï¼š\n\n"
    "ã€äº§å“ä¸å®šä½ã€‘ä¸€å¥è¯æ¦‚è¿°äº§å“åç§°å’Œæ ¸å¿ƒå®šä½ç­–ç•¥\n"
    "ã€Agent é…ç½®ã€‘Star Agent æ•°é‡å’Œç±»å‹åˆ—è¡¨ï¼ˆä¸€è¡Œä¸€ä¸ªï¼Œé™„æ‹¬å·ä¸­çš„ä¸­æ–‡è§’è‰²æè¿°ï¼‰ï¼Œ"
    "Sea Agent æ•°é‡å’Œç±»å‹åˆ—è¡¨ï¼ˆåŒä¸Šæ ¼å¼ï¼‰\n"
    "ã€ä¼ æ’­å‚æ•°ã€‘wave_time_windowã€energy_decay_per_waveã€é¢„ä¼°/å®é™…æ³¢æ¬¡æ•°ã€ç§å­èƒ½é‡\n"
    "ã€ä¼ æ’­æ¨¡å¼æ‘˜è¦ã€‘3-5å¥è¯æ¦‚è¿°ä¼ æ’­æ›²çº¿å½¢æ€ã€å…³é”®è½¬æŠ˜ç‚¹ã€ä¸»å¯¼ä¼ æ’­è·¯å¾„\n"
    "ã€Agent å“åº”æ¨¡å¼ã€‘é€ Agent åˆ—å‡ºï¼š\n"
    "  - Agent ID + ä¸­æ–‡è§’è‰²åï¼ˆå¦‚ star_xxxã€Œæ˜Ÿ-XXè¾¾äººã€ï¼‰\n"
    "  - ä¸»è¦è¡Œä¸ºæ¨¡å¼ï¼ˆabsorb/comment/mutate/create/ignoreï¼‰\n"
    "  - **å³°å€¼èƒ½é‡æ•°å€¼**ï¼ˆå¦‚ peak E=0.46ï¼‰å’Œæœ«æœŸèƒ½é‡æ•°å€¼\n"
    "  - è¡Œä¸ºè½¬å˜èŠ‚ç‚¹ï¼ˆå¦‚ W9 ä» comment è½¬ ignoreï¼‰\n"
    "ã€åˆè®®åº­è¯„åˆ†ã€‘é€è§’è‰²åˆ—å‡ºäº”ç»´è¯„åˆ†ï¼ˆdemand_resonance / propagation_potential / "
    "competitive_differentiation / adoption_friction / sustained_valueï¼‰ï¼Œæ ‡æ³¨æ”¶æ•›çŠ¶æ€\n"
    "ã€é¢„æµ‹ç»“è®ºã€‘æ–¹å‘ï¼ˆrise/stable/declineï¼‰å’Œä¸€å¥è¯æ‘˜è¦\n"
    "ã€å…³é”®æ—¶é—´çº¿ã€‘é€æ¡åˆ—å‡º TIMELINE ä¸­çš„èŠ‚ç‚¹\n"
    "ã€åˆ†å‰ç‚¹ã€‘é€æ¡åˆ—å‡º BIFURCATION ä¸­çš„èŠ‚ç‚¹å’Œå¯èƒ½è·¯å¾„\n"
    "ã€Agent æ´å¯Ÿã€‘é€ Agent åˆ—å‡ºæ ¸å¿ƒæ´å¯Ÿå’Œå»ºè®®è¡ŒåŠ¨ï¼ˆä¸€è¡Œä¸€ä¸ªï¼‰\n"
)


async def _preprocess_single_log(
    condensed_log: str,
    group_label: str,
    router: ModelRouter,
) -> Optional[str]:
    """ç”¨ LLM æå–å•ç»„å‹ç¼©æ—¥å¿—ç»“æ„åŒ–æ‘˜è¦ã€‚ / Use LLM to extract structured summary from a condensed single-group log."""
    logger.info("é¢„å¤„ç† %s ç»„æ—¥å¿—ï¼ˆLLM ç»“æ„åŒ–æ‘˜è¦ï¼‰...", group_label)
    user_msg = f"ä»¥ä¸‹æ˜¯{group_label}ç»„çš„æ¨¡æ‹Ÿæ—¥å¿—æ•°æ®ï¼š\n\n{condensed_log}"
    try:
        return await call_llm(router, "omniscient", _PREPROCESS_SYSTEM, user_msg)
    except Exception as exc:
        logger.warning("%s ç»„é¢„å¤„ç†å¤±è´¥: %s", group_label, exc)
        return None


# =============================================================================
# A/B å¯¹æ¯”æŠ¥å‘Šç”Ÿæˆå™¨ï¼ˆä¸‰é˜¶æ®µï¼šå‹ç¼©â†’é¢„å¤„ç†â†’å¯¹æ¯”ï¼‰ / A/B comparison report generator (3-stage pipeline)
# =============================================================================

async def generate_ab_comparison_report(
    md_path_a: str,
    md_path_b: str,
    config_file: str,
    grade_a: str,
    details_a: Dict[str, Any],
    grade_b: str,
    details_b: Dict[str, Any],
    role: str = "omniscient",
    max_llm_calls: int = 20,
) -> Optional[str]:
    """ä¸‰é˜¶æ®µç”Ÿæˆ A/B å¯¹æ¯”æŠ¥å‘Šã€‚ / Generate A/B comparison report in three stages.

    1) ç¨‹åºåŒ–å‹ç¼©ï¼›2) LLM é¢„å¤„ç†ï¼›3) æ³¨å…¥è¯„åˆ†çŸ©é˜µååšå››è½®æ·±åº¦å¯¹æ¯”ã€‚ / 1) Programmatic compression; 2) LLM preprocessing; 3) Four-round deep comparison with scoring matrix context.
    """
    # é˜¶æ®µé›¶ï¼šä» JSON å®Œæ•´æ—¥å¿—ä¸­æå– Agent å³°å€¼èƒ½é‡
    json_path_a = str(Path(md_path_a).with_suffix(".json"))
    json_path_b = str(Path(md_path_b).with_suffix(".json"))
    peaks_a: Dict[str, float] = {}
    peaks_b: Dict[str, float] = {}
    try:
        peaks_a = _extract_agent_peak_energies(json_path_a)
        peaks_b = _extract_agent_peak_energies(json_path_b)
        logger.info(
            "Agent å³°å€¼èƒ½é‡æå–å®Œæˆï¼ˆJSONï¼‰: Aç»„ %d ä¸ªèŠ‚ç‚¹, Bç»„ %d ä¸ªèŠ‚ç‚¹",
            len(peaks_a), len(peaks_b),
        )
    except Exception as exc:
        logger.warning("JSON å³°å€¼èƒ½é‡æå–å¤±è´¥ï¼ˆå°†åœ¨æŠ¥å‘Šä¸­ç¼ºçœï¼‰: %s", exc)

    # æ„å»ºå¸¦è¯„åˆ† + å³°å€¼èƒ½é‡æ•°æ®çš„æŠ¥å‘Šè½®æ¬¡
    rounds = _build_ab_comparison_rounds(
        grade_a, details_a, grade_b, details_b, peaks_a, peaks_b,
    )

    # é˜¶æ®µä¸€ï¼šç¨‹åºåŒ–å‹ç¼© MD æ—¥å¿—
    try:
        raw_a = Path(md_path_a).read_text(encoding="utf-8")
        raw_b = Path(md_path_b).read_text(encoding="utf-8")
    except Exception as exc:
        logger.error("è¯»å– MD æ–‡ä»¶å¤±è´¥: %s", exc)
        return None

    condensed_a = _condense_md_for_comparison(raw_a)
    condensed_b = _condense_md_for_comparison(raw_b)
    logger.info(
        "æ—¥å¿—å‹ç¼©å®Œæˆ: Aç»„ %dKBâ†’%dKB, Bç»„ %dKBâ†’%dKB",
        len(raw_a) // 1024, len(condensed_a) // 1024,
        len(raw_b) // 1024, len(condensed_b) // 1024,
    )

    try:
        router = ModelRouter(config_file=config_file, max_llm_calls=max_llm_calls)
    except Exception as exc:
        logger.warning("åˆ›å»º LLM è·¯ç”±å™¨å¤±è´¥: %s", exc)
        return None

    # é˜¶æ®µäºŒï¼šLLM é¢„å¤„ç†ï¼ˆåˆ†åˆ«å¯¹æ¯ç»„åšç»“æ„åŒ–æ‘˜è¦ï¼‰
    print("  â–¶ é˜¶æ®µä¸€ï¼šé¢„å¤„ç†Aç»„æ—¥å¿—...")
    summary_a = await _preprocess_single_log(condensed_a, "A", router)
    print("  â–¶ é˜¶æ®µäºŒï¼šé¢„å¤„ç†Bç»„æ—¥å¿—...")
    summary_b = await _preprocess_single_log(condensed_b, "B", router)

    if not summary_a or not summary_b:
        logger.warning("é¢„å¤„ç†é˜¶æ®µå¤±è´¥ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨å‹ç¼©æ—¥å¿—è¿›è¡Œå¯¹æ¯”")
        summary_a = summary_a or condensed_a
        summary_b = summary_b or condensed_b

    # é˜¶æ®µä¸‰ï¼šåˆå¹¶ä¸¤ç»„æ‘˜è¦ï¼Œè¿›è¡Œ 4 è½®å¯¹æ¯”åˆ†æ
    combined = (
        "â•" * 40 + "\n"
        "Aç»„ç»“æ„åŒ–æ‘˜è¦ï¼ˆé»‘é•œÂ·é›¶æ„Ÿ â€” 0ç³–0è„‚0å¡0ä»£ç³– Â· å¥åº·ç„¦è™‘å®šä½ï¼‰\n"
        "â•" * 40 + "\n\n"
        f"{summary_a}\n\n"
        "â•" * 40 + "\n"
        "Bç»„ç»“æ„åŒ–æ‘˜è¦ï¼ˆé»‘é•œÂ·äº‘å— â€” äº‘å—äº§åœ° SCA 85+ Â· å“è´¨æº¯æºå®šä½ï¼‰\n"
        "â•" * 40 + "\n\n"
        f"{summary_b}"
    )

    parts: List[str] = []
    for i, rd in enumerate(rounds, 1):
        print(f"  â–¶ å¯¹æ¯”åˆ†æç¬¬ {i}/{len(rounds)} è½®ï¼š{rd.label}")
        logger.info("A/Bå¯¹æ¯”æŠ¥å‘Š â€” ç¬¬ %d/%d è½®ï¼š%s", i, len(rounds), rd.label)
        user_msg = combined
        if rd.extra_user_context:
            user_msg += "\n\n" + rd.extra_user_context
        try:
            text = await call_llm(router, role, rd.system_prompt, user_msg)
            if text:
                parts.append(text)
        except Exception as exc:
            logger.warning("ç¬¬%dè½®å¯¹æ¯”åˆ†æå¤±è´¥: %s", i, exc)

    return "\n\n" + ("â”€" * 40 + "\n\n").join(parts) if parts else None


def _save_ab_report(
    report: str,
    md_path_a: str,
    md_path_b: str,
    grade_a: str = "N/A",
    grade_b: str = "N/A",
) -> Optional[str]:
    """å°† A/B å¯¹æ¯”æŠ¥å‘Šä¿å­˜åˆ° `ripple_outputs/`ã€‚ / Save A/B comparison report to `ripple_outputs/`."""
    output_dir = REPO_ROOT / "ripple_outputs"
    output_dir.mkdir(exist_ok=True)

    # ä»æ–‡ä»¶åä¸­æå– run_id
    run_id_a = Path(md_path_a).stem.split("_")[-1] if md_path_a else "unknown"
    run_id_b = Path(md_path_b).stem.split("_")[-1] if md_path_b else "unknown"

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{timestamp}_ab_compare_{run_id_a}_vs_{run_id_b}.md"
    filepath = output_dir / filename

    header = (
        f"# A/B æµ‹è¯•å¯¹æ¯”æŠ¥å‘Šï¼šå†»å¹²å’–å•¡å®šä½ç­–ç•¥ PMF éªŒè¯\n\n"
        f"- ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().isoformat()}\n"
        f"- Aç»„ run_idï¼š{run_id_a}ï¼ˆPMF Grade: {grade_a}ï¼‰\n"
        f"- Bç»„ run_idï¼š{run_id_b}ï¼ˆPMF Grade: {grade_b}ï¼‰\n"
        f"- Aç»„äº§å“ï¼šé»‘é•œÂ·é›¶æ„Ÿï¼ˆ0ç³–0è„‚0å¡0ä»£ç³– Â· å¥åº·ç„¦è™‘å®šä½ï¼‰\n"
        f"- Bç»„äº§å“ï¼šé»‘é•œÂ·äº‘å—ï¼ˆäº‘å—äº§åœ° SCA 85+ Â· å“è´¨æº¯æºå®šä½ï¼‰\n"
        f"- æ¨¡æ‹Ÿå¹³å°ï¼šæŠ–éŸ³ç”µå•†ï¼ˆç®—æ³•æ¨èæµ + ç›´æ’­å¸¦è´§ï¼‰\n"
        f"- æ¨¡æ‹Ÿæ—¶é•¿ï¼š{SIMULATION_HOURS}å°æ—¶\n\n"
        f"## æ•°æ®æºå¼•ç”¨\n\n"
        f"- Aç»„ç²¾ç®€æ—¥å¿—ï¼š{md_path_a}\n"
        f"- Bç»„ç²¾ç®€æ—¥å¿—ï¼š{md_path_b}\n\n"
        f"---\n\n"
    )

    filepath.write_text(header + report, encoding="utf-8")
    return str(filepath)


# =============================================================================
# A/B å¯¹æ¯”æµç¨‹å…¥å£ï¼ˆab ä¸ compare å…±ç”¨ï¼‰ / A/B comparison entry (shared by `ab` and `compare`)
# =============================================================================

async def run_comparison(
    md_path_a: str,
    md_path_b: str,
    config_file: Optional[str],
    no_report: bool = False,
) -> None:
    """åŸºäºä¸¤ä¸ªæ—¢æœ‰ .md æ–‡ä»¶æ‰§è¡Œ A/B å¯¹æ¯”æµç¨‹ã€‚ / Run A/B comparison workflow from two existing .md files."""

    # è§£æ PMF Grade
    grade_a, details_a = extract_pmf_grade(md_path_a)
    grade_b, details_b = extract_pmf_grade(md_path_b)

    # æ‰“å°è¯„çº§é€Ÿè§ˆ
    print()
    print("â•" * 70)
    print("  A/B æµ‹è¯• â€” PMF è¯„çº§é€Ÿè§ˆ")
    print("â•" * 70)
    print(f"  Aç»„ï¼ˆé»‘é•œÂ·é›¶æ„Ÿ / å¥åº·ç„¦è™‘å®šä½ï¼‰: {grade_a}")
    if details_a.get("dimension_averages"):
        dims = details_a["dimension_averages"]
        print(f"       ç»´åº¦å‡åˆ†: {' | '.join(f'{k}={v}' for k, v in dims.items())}")
        print(f"       æ€»ä½“å‡åˆ†: {details_a.get('overall_average', 'N/A')}")
    print(f"  Bç»„ï¼ˆé»‘é•œÂ·äº‘å— / å“è´¨æº¯æºå®šä½ï¼‰: {grade_b}")
    if details_b.get("dimension_averages"):
        dims = details_b["dimension_averages"]
        print(f"       ç»´åº¦å‡åˆ†: {' | '.join(f'{k}={v}' for k, v in dims.items())}")
        print(f"       æ€»ä½“å‡åˆ†: {details_b.get('overall_average', 'N/A')}")
    print("â•" * 70)

    # ç”Ÿæˆ A/B å¯¹æ¯”æŠ¥å‘Š
    if not no_report and config_file:
        print()
        print("â”" * 70)
        print("  æ­£åœ¨ç”Ÿæˆ A/B å¯¹æ¯”åˆ†ææŠ¥å‘Šï¼ˆé¢„å¤„ç† + 4è½®æ·±åº¦å¯¹æ¯”ï¼‰...")
        print("â”" * 70)

        report = await generate_ab_comparison_report(
            md_path_a, md_path_b, config_file,
            grade_a, details_a, grade_b, details_b,
        )
        if report:
            print()
            print("â•" * 70)
            print("  A/B æµ‹è¯• â€” æ·±åº¦å¯¹æ¯”åˆ†ææŠ¥å‘Š")
            print("â•" * 70)
            print(report)
            print("â•" * 70)

            report_path = _save_ab_report(
                report, md_path_a, md_path_b, grade_a, grade_b,
            )
            if report_path:
                print(f"\n  å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜è‡³ï¼š{report_path}")
        else:
            print("\n  âš  A/B å¯¹æ¯”æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ llm_config.yamlã€‚")


# =============================================================================
# ä¸»å‡½æ•° / Main
# =============================================================================

_EXTRA_SUMMARY = {
    "ensemble_runs": ENSEMBLE_RUNS,
    "deliberation_rounds": DELIBERATION_ROUNDS,
}


async def main() -> None:
    parser = create_arg_parser(
        "Ripple A/B æµ‹è¯• â€” å†»å¹²å’–å•¡å®šä½ç­–ç•¥ Ã— æŠ–éŸ³ç”µå•† PMF éªŒè¯ï¼ˆ72hï¼‰",
        modes=("a", "b", "ab", "compare"),
        default_waves=DEFAULT_WAVES,
    )
    # compare æ¨¡å¼ä¸“ç”¨å‚æ•°ï¼šç›´æ¥ä¼ å…¥æ—¢æœ‰ .md æ–‡ä»¶è·¯å¾„ / Compare-mode args: pass existing .md file paths directly
    parser.add_argument(
        "--file-a",
        type=str,
        default=None,
        help="Aç»„æ¨¡æ‹Ÿç»“æœ .md æ–‡ä»¶è·¯å¾„ï¼ˆcompare æ¨¡å¼å¿…å¡«ï¼‰",
    )
    parser.add_argument(
        "--file-b",
        type=str,
        default=None,
        help="Bç»„æ¨¡æ‹Ÿç»“æœ .md æ–‡ä»¶è·¯å¾„ï¼ˆcompare æ¨¡å¼å¿…å¡«ï¼‰",
    )
    args = parser.parse_args()
    waves = args.waves
    cfg = config_file_path()
    no_report = args.no_report

    # â”€â”€ compare æ¨¡å¼ï¼šç›´æ¥ä»å·²æœ‰ MD æ–‡ä»¶ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š â”€â”€
    if args.mode == "compare":
        if not args.file_a or not args.file_b:
            parser.error("compare æ¨¡å¼éœ€è¦åŒæ—¶æä¾› --file-a å’Œ --file-b å‚æ•°")
        if not Path(args.file_a).exists():
            parser.error(f"Aç»„æ–‡ä»¶ä¸å­˜åœ¨: {args.file_a}")
        if not Path(args.file_b).exists():
            parser.error(f"Bç»„æ–‡ä»¶ä¸å­˜åœ¨: {args.file_b}")

        print()
        print("â”" * 70)
        print("  A/B å¯¹æ¯”æ¨¡å¼ â€” ä»å·²æœ‰æ¨¡æ‹Ÿç»“æœç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š")
        print(f"  Aç»„æ–‡ä»¶: {args.file_a}")
        print(f"  Bç»„æ–‡ä»¶: {args.file_b}")
        print("â”" * 70)

        await run_comparison(args.file_a, args.file_b, cfg, no_report)
        return

    # â”€â”€ Aç»„å•ç‹¬è¿è¡Œ â”€â”€
    if args.mode == "a":
        result_a = await run_and_interpret(
            "Aç»„ PMF éªŒè¯ï¼ˆé»‘é•œÂ·é›¶æ„Ÿï¼‰",
            run_a(waves),
            cfg,
            report_rounds=_build_individual_report_rounds(),
            extra_summary_fields=_EXTRA_SUMMARY,
            no_report=no_report,
        )
        md_path = result_a.get("compact_log_file")
        if md_path:
            grade, details = extract_pmf_grade(md_path)
            print(f"\n  Aç»„ PMF Grade: {grade} (å‡åˆ† {details.get('overall_average', 'N/A')})")

    # â”€â”€ Bç»„å•ç‹¬è¿è¡Œ â”€â”€
    elif args.mode == "b":
        result_b = await run_and_interpret(
            "Bç»„ PMF éªŒè¯ï¼ˆé»‘é•œÂ·äº‘å—ï¼‰",
            run_b(waves),
            cfg,
            report_rounds=_build_individual_report_rounds(),
            extra_summary_fields=_EXTRA_SUMMARY,
            no_report=no_report,
        )
        md_path = result_b.get("compact_log_file")
        if md_path:
            grade, details = extract_pmf_grade(md_path)
            print(f"\n  Bç»„ PMF Grade: {grade} (å‡åˆ† {details.get('overall_average', 'N/A')})")

    # â”€â”€ A/B åŒç»„è¿è¡Œ + å¯¹æ¯”æŠ¥å‘Š â”€â”€
    elif args.mode == "ab":
        result_a = await run_and_interpret(
            "Aç»„ PMF éªŒè¯ï¼ˆé»‘é•œÂ·é›¶æ„Ÿï¼‰",
            run_a(waves),
            cfg,
            report_rounds=None,
            extra_summary_fields=_EXTRA_SUMMARY,
            no_report=True,
        )
        result_b = await run_and_interpret(
            "Bç»„ PMF éªŒè¯ï¼ˆé»‘é•œÂ·äº‘å—ï¼‰",
            run_b(waves),
            cfg,
            report_rounds=None,
            extra_summary_fields=_EXTRA_SUMMARY,
            no_report=True,
        )

        md_a = result_a.get("compact_log_file", "")
        md_b = result_b.get("compact_log_file", "")
        if md_a and md_b:
            await run_comparison(md_a, md_b, cfg, no_report)
        else:
            print("\n  âš  æ¨¡æ‹Ÿè¾“å‡ºæ–‡ä»¶ç¼ºå¤±ï¼Œæ— æ³•ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Šã€‚")


if __name__ == "__main__":
    asyncio.run(main())
