# OASIS: Open Agent Social Interaction Simulations with One Million Agents

**论文深度分析**

---

## 目录

1. [论文基本信息](#1-论文基本信息)
2. [核心定位与研究动机](#2-核心定位与研究动机)
3. [系统架构：五大模块](#3-系统架构五大模块)
   - 3.1 Environment Server
   - 3.2 RecSys（推荐系统）
   - 3.3 Agent Module
   - 3.4 Time Engine
   - 3.5 Scalable Inferencer
4. [信息传播动力学](#4-信息传播动力学)
   - 4.1 传播链路全景
   - 4.2 RecSys 作为传播中枢
   - 4.3 Agent 决策机制
   - 4.4 级联放大与自然衰减
5. [网络拓扑与规模扩展](#5-网络拓扑与规模扩展)
6. [三大涌现现象实验](#6-三大涌现现象实验)
   - 6.1 信息传播（Information Spreading）
   - 6.2 群体极化（Group Polarization）
   - 6.3 羊群效应（Herd Effect）
7. [百万 Agent 模拟](#7-百万-agent-模拟)
8. [消融实验](#8-消融实验)
9. [局限性分析](#9-局限性分析)
10. [对 Ripple 项目的启示](#10-对-ripple-项目的启示)

---

## 1. 论文基本信息

- **标题：** OASIS: Open Agent Social Interaction Simulations with One Million Agents
- **arXiv：** 2411.11581
- **机构：** 多机构合作
- **核心贡献：** 提出一个可扩展的、基于 LLM Agent 的社交媒体模拟器，支持 X (Twitter) 和 Reddit 两种平台环境，最大规模可达 100 万个 Agent，并在信息传播、群体极化、羊群效应三个维度上与真实数据对比验证

---

## 2. 核心定位与研究动机

OASIS 试图解决的核心问题：**如何在可控的模拟环境中复现真实社交平台上的群体涌现现象？**

传统的 Agent-Based Model（ABM）依赖手工规则定义 Agent 行为，难以捕捉人类决策的复杂性。OASIS 的创新在于用 LLM 替代规则引擎作为 Agent 的"大脑"，让每个 Agent 基于自身画像、记忆和推荐内容，通过自然语言推理来做出社交行为决策。

与同期工作的对比：
- **Smallville（Generative Agents）：** 25 个 Agent 的面对面小镇模拟，无推荐系统
- **S3、HiSim：** 社交模拟但规模有限
- **OASIS 的独特性：** 同时具备 **动态社交网络 + 完整推荐系统 + 平台特异性环境 + 百万级规模**

---

## 3. 系统架构：五大模块

OASIS 由五个核心模块组成，形成一个闭环的模拟系统：

```
┌─────────────────────────────────────────────────────────┐
│                    OASIS 系统架构                         │
│                                                          │
│  ┌──────────────┐    ┌──────────┐    ┌───────────────┐  │
│  │ Environment  │←──→│  RecSys  │←──→│ Agent Module  │  │
│  │   Server     │    │          │    │ (LLM + Memory │  │
│  │ (关系数据库)  │    │(推荐算法) │    │  + 21 Actions)│  │
│  └──────┬───────┘    └──────────┘    └───────┬───────┘  │
│         │                                     │          │
│  ┌──────┴───────┐              ┌──────────────┴───────┐ │
│  │ Time Engine  │              │ Scalable Inferencer  │ │
│  │(24维活跃概率) │              │ (异步多GPU分布推理)   │ │
│  └──────────────┘              └──────────────────────┘ │
└─────────────────────────────────────────────────────────┘
```

### 3.1 Environment Server（环境服务器）

维护整个平台的全局状态，采用关系数据库，包含六张核心表：

| 表 | 存储内容 |
|---|---|
| **users** | 用户信息（画像、自我描述、历史帖子） |
| **posts** | 所有帖子及元数据（点赞数、创建时间） |
| **comments** | 评论及其元数据 |
| **relations** | 各类关系（关注、点赞、屏蔽等） |
| **traces** | 完整的行为轨迹历史 |
| **recommendations** | RecSys 的推荐输出结果 |

数据库随模拟进程**实时动态更新**——新用户注册、新帖发布、新关系建立都会立即反映在全局状态中。

### 3.2 RecSys（推荐系统）

推荐系统是 OASIS 信息传播的**核心中枢**，决定每个 Agent 能"看到"哪些内容。针对不同平台实现了不同的推荐算法。

#### X (Twitter) 平台推荐

帖子通过两条通路到达 Agent：

**In-network（关注流）：** 来自已关注用户的帖子，按热度（点赞数）排序。

**Out-of-network（发现流）：** 来自非关注用户的帖子，按综合得分排序：

```
Score = R × F × S
```

三个因子分别为：

- **R（Recency，时效性）：**
  ```
  R = ln((271.8 - (t_current - t_created)) / 100)
  ```
  帖子越新得分越高，随时间对数衰减。当 `t_current - t_created` 接近 271.8 时，R 趋近于 0。

- **F（Fan count，影响力）：**
  ```
  F = max(1, log₁₀₀₀(fan_count + 1))
  ```
  粉丝数的对数缩放。保证最低值为 1（即零粉丝用户不会被完全过滤），大 V 有适度加成但不会压倒性主导。

- **S（Similarity，语义匹配）：**
  ```
  S = cosine_similarity(E_post, E_user)
  ```
  使用 **TwHIN-BERT**（在 70 亿条推文上预训练的嵌入模型）分别计算帖子内容和用户兴趣的嵌入向量，取余弦相似度。

#### Reddit 平台推荐

使用经典的 hot score 算法：

```
h = log₁₀(max(|u - d|, 1)) + sign(u - d) × (t - t₀) / 45000
```

其中 `u` = 赞数，`d` = 踩数，`t` = 提交时间，`t₀` = 参考时间。这个公式让早期获得高赞的内容在排序中占据优势。

### 3.3 Agent Module（Agent 模块）

每个 Agent 由 LLM 驱动，包含两个子模块：

**记忆模块（Memory）：** 存储 Agent 遇到过的信息，包括看过的帖子、自己的历史行为及其推理过程。

**行为模块（Action）：** 支持 **21 种动作**：

| 类别 | 动作 |
|---|---|
| 内容创作 | 创建帖子、转发（repost） |
| 内容互动 | 点赞帖子、取消点赞、踩帖子 |
| 评论互动 | 创建评论、点赞评论、踩评论 |
| 社交关系 | 关注、取消关注、屏蔽 |
| 信息获取 | 搜索帖子、搜索用户、查看趋势、刷新 |
| 注册 | 注册账号 |
| 空操作 | 什么都不做（do nothing） |

**决策机制：Chain-of-Thought（CoT）推理**

Agent 收到推荐帖列表后，LLM 按结构化格式输出：
1. 先在 `reason` 字段生成推理过程（为什么要执行某个动作）
2. 然后在 `functions` 字段输出具体动作调用

这种 CoT 机制既提升了行为的可解释性，也让研究者能追溯 Agent 决策的逻辑链。

### 3.4 Time Engine（时间引擎）

每个 Agent 拥有一个 **24 维活跃概率向量**，表示其在一天 24 小时中每个小时的活跃概率：

```
P_ij = f_ij / max_k(f_kj)
```

其中 `f_ij` 是第 `i` 个 Agent 在第 `j` 小时的历史活跃频率。

关键设计：
- Agent 按概率被激活，**而非同步激活**
- 每个 simulation time step = **3 分钟**
- 引入了**时间异质性**——模拟了"不同人在不同时段上线"的真实特征
- 可选的线性映射模式用于 time step 内的精确时间戳

### 3.5 Scalable Inferencer（可扩展推理器）

为支持百万级 Agent，采用分布式异步架构：

- Agent、Environment Server、推理服务作为**独立模块**运行
- 通过**异步消息队列**交换数据
- Agent 可并发发送多个推理请求
- **GPU Manager** 在可用设备间负载均衡
- 支持多机多卡部署

---

## 4. 信息传播动力学

这是 OASIS 与 Ripple 项目最直接相关的部分。OASIS 中的信息传播不是基于显式的传播模型（如 SIR/IC/LT），而是通过 **RecSys 推荐 → Agent LLM 决策 → 环境状态更新** 的闭环自然涌现。

### 4.1 传播链路全景

```
Agent A 创帖
    ↓
写入 Environment Server（posts 表，初始 likes=0）
    ↓
RecSys 按 R×F×S 得分排序，将帖子推荐给候选 Agent
    ↓
Time Engine 按概率激活 Agent B
    ↓
Agent B 收到推荐帖列表 + 元信息（likes, comments 数量...）
    ↓
LLM CoT 推理 → 决定：转发 / 点赞 / 评论 / 忽略
    ↓
动作回写 Environment Server → 帖子 likes+1 或 repost 数+1
    ↓
RecSys 重新排序（热度上升 → 得分提高）→ 更多 Agent 看到
    ↓
循环，直到帖子自然衰减（R 因子随时间降低趋近于 0）
```

### 4.2 RecSys 作为传播中枢

RecSys 在信息传播中扮演双重角色：

**放大器：** 获得早期互动的帖子在排序中得分提高，被更多 Agent 看到，形成正反馈循环——这正是真实社交平台"爆款"的产生机制。

**过滤器：** 低相关度（S 值低）或过时（R 值低）的帖子被排到后面，Agent 看不到，传播自然终止。

**消融实验的关键发现：** 去掉 RecSys 后，信息传播会**过早终止**。这证明了推荐系统不仅是"信息分发渠道"，更是维持传播动力学运转的**必要条件**。TwHIN-BERT（社交媒体专用嵌入）的效果显著优于通用 BERT。

### 4.3 Agent 决策机制

Agent 在每个 time step 的决策流程：

1. **接收推荐：** RecSys 推送一组帖子，每条帖子附带元信息（内容、点赞数、评论数、评论的点赞数）
2. **记忆上下文：** 从记忆模块中检索与当前帖子相关的历史信息
3. **CoT 推理：** LLM 综合考虑 Agent 的个人画像、记忆、帖子内容和社交信号，生成推理过程
4. **输出动作：** 从 21 种动作中选择一个执行

关键细节：**Agent 能看到帖子的社交信号**（如 1000 个点赞 vs 2 个点赞），这些信号直接影响决策——这也是羊群效应实验的机制基础。

### 4.4 级联放大与自然衰减

传播的正反馈循环：

```
帖子获得互动 → likes/repost 数增加
    → RecSys 热度排名上升
    → 更多 Agent 被推荐到此帖
    → 更多互动 → 继续放大
```

传播的自然衰减：

```
时间推移 → R（时效性）因子衰减
    → 帖子在 RecSys 中排名下降
    → 越来越少的 Agent 看到
    → 互动减少 → 传播终止
```

这种"先爆发后衰减"的模式与真实社交媒体的信息传播曲线高度一致。

---

## 5. 网络拓扑与规模扩展

### 用户生成策略

OASIS 采用**核心用户 + 合成用户**的两层结构：

| 用户类型 | 来源 | 特征 |
|---|---|---|
| **核心用户（Core Users）** | 真实数据集（Twitter15/16） | 真实画像、真实关注关系、历史帖子 |
| **普通用户（Ordinary Users）** | LLM 生成的合成用户 | 从人口分布采样（年龄、MBTI、职业、兴趣），LLM 生成详细 persona |

### 网络构建

- 合成用户通过**兴趣匹配**与核心用户建立关注关系
- 关注核心用户的概率为 **0.1~0.2**
- 网络整体保持**无标度（scale-free）特性**——少数核心节点拥有大量连接，多数普通节点连接较少
- 这种幂律分布是真实社交网络的基本特征

### 规模性能

| 规模 | 硬件 | 每 time step 耗时 | 吞吐量 |
|---|---|---|---|
| ~200 Agent | 少量 GPU | 较短 | — |
| 100K Agent | 5 × A100 | ~3 小时 | — |
| 1M Agent | 27 × A100 | ~18 小时 | 48.5K tweets + 97.1K comments / step |

---

## 6. 三大涌现现象实验

### 6.1 信息传播（Information Spreading）

**平台：** X (Twitter)
**数据：** Twitter15 和 Twitter16 数据集，198 条真实传播链，覆盖 9 个类别
**初始化：** Agent 使用真实用户画像、关注关系、历史帖子

**度量指标：**

| 指标 | 定义 |
|---|---|
| **Scale（规模）** | 随时间参与传播的用户数量 |
| **Depth（深度）** | 源帖传播图的最大深度（转发链长度） |
| **Max Breadth（最大宽度）** | 任意深度上参与人数的最大值 |

**评价方法：** 模拟曲线与真实数据曲线之间的 Normalized RMSE (NRMSE)

**结果：**
- **Scale 和 Max Breadth：** NRMSE 约 **30%**，无显著偏移，模拟结果与真实数据在传播规模和宽度上基本吻合
- **Depth：** 模拟的传播深度**系统性偏低**——Agent 的转发链不够长

**深度偏低的原因分析：**
- OASIS 的 RecSys 是真实推荐系统的简化版本，无法精确模拟中间用户的曝光和转发行为
- 用户画像精度不足——简化的 persona 无法还原每个中间节点的真实转发倾向
- 论文原文："the depth of OASIS simulation propagation is smaller than the real-world propagation"

### 6.2 群体极化（Group Polarization）

**实验设计：** 196 个真实核心用户讨论一个经典困境问题（角色 Halen 是否应该写一部冒险小说）。模拟规模从 196 扩展到 100,000 Agent。每 10 个 time step，由 GPT-4o-mini 评估意见是否变得"比第 0 轮更极端"。

**关键发现：**

- **未审查模型（Uncensored Llama-3-8B）** 展现出显著更强的极化，使用更极端的措辞如 "always better"
- **对齐模型** 的极化程度较低，但仍可观察到
- 随交互进行，Agent 的回复**逐渐趋于保守**（可能是 LLM 安全对齐的副作用）
- **规模效应：** 更大的 Agent 群体产生了**更多样化的意见**，且意见质量（按 Safe-RLHF 标准评估的有用性）随规模提升：196 < 10,196 < 100,196

### 6.3 羊群效应（Herd Effect）

**平台：** Reddit
**数据：** 116,932 条真实 Reddit 评论，覆盖 7 个话题
**实验设计：** 复现 Muchnik et al. (2013) 的经典实验，三组条件：

| 条件 | 操作 |
|---|---|
| **Down-treated** | 给内容一个初始踩 |
| **Control** | 不做任何初始操作 |
| **Up-treated** | 给内容一个初始赞 |

模拟 40 个 time step，每组 3,600-10,000 生成用户。

**关键发现：**

- **Up-treated（初始正面）：** Agent 与人类行为高度一致
- **Down-treated（初始负面）：** Agent 表现出比人类**显著更强的从众倾向**——"agents tend to follow others' behavior by further disliking the post"
- 人类在面对负面初始信号时展现出更强的**批判性思维**，会独立判断而非盲从
- **规模依赖：** 100 个 Agent 时羊群效应不显著；扩展到 10,000 Agent 时效应明显，尤其在 down-treated 组

---

## 7. 百万 Agent 模拟

在 27 块 A100 GPU 上运行 100 万 Agent 的模拟，关键观察：

- 每个 time step 产生 **48.5K 新推文 + 97.1K 新评论**
- **谣言的传播范围显著大于真实信息**
- Agent 随时间推移逐渐形成**孤立群体（isolated groups）**——信息茧房的涌现
- 每个 time step 耗时约 18 小时

---

## 8. 消融实验

| 消融条件 | 影响 |
|---|---|
| **去掉 RecSys** | 传播过早终止——证明推荐系统是传播动力的必要条件 |
| **通用 BERT 替代 TwHIN-BERT** | 推荐精度下降，传播模式偏离真实数据 |
| **去掉时间特征（24维活跃概率）** | NRMSE 显著上升——时间真实性对传播模拟至关重要 |
| **不同 LLM 模型对比** | Qwen1.5-7B-Chat、Internlm2-chat-20b、Llama-3-8B-Instruct 在 28 个测试话题上表现相当 |

---

## 9. 局限性分析

1. **传播深度系统性偏低：** 简化的 RecSys 和用户画像无法精确建模中间节点的转发行为
2. **Agent 从众倾向过强：** LLM Agent 比真实人类更容易被社交信号影响，缺乏批判性思维
3. **计算成本极高：** 百万规模需要 27 块 A100，每步 18 小时——难以进行快速迭代实验
4. **平台覆盖有限：** 仅实现了 X 和 Reddit，未覆盖短视频（抖音/TikTok）等内容形态
5. **Agent 画像精度：** 合成用户的 persona 生成可能与真实用户行为分布存在偏差

---

## 10. 对 Ripple 项目的启示

| 维度 | OASIS 的做法 | Ripple 可借鉴/应注意的点 |
|---|---|---|
| **RecSys 作为传播中枢** | 实现平台特异性推荐算法，消融实验证明其不可或缺 | Ripple 的 Ripple Propagator 需要整合各平台 RecSys 的核心逻辑，而非仅用抽象的传播模型（IC/LT） |
| **Agent 粒度** | 每个 Agent = 一个用户，无分层 | Ripple 的 Star-Sea 分层策略在成本控制上有优势，但需确保 SeaAgent 的集群决策仍能产生足够的行为多样性 |
| **传播深度不足** | 级联深度偏低是核心痛点 | Ripple 的能量衰减模型 + 显式 ripple 传播协议可能在深度级联建模上更有优势，值得重点验证 |
| **羊群效应过强** | LLM Agent 从众倾向超过真实人类 | SeaAgent 的 prompt 设计需要引入"个体差异性"和"批判性思维"调节参数，避免群体行为过度一致 |
| **时间异质性** | 24 维活跃概率向量，概率激活 | Ripple 的 Wave Clock 设计可以参考这种时间分布建模，尤其要考虑不同平台的活跃时间特征差异 |
| **规模-质量权衡** | 更大规模→更多样化意见→但计算成本指数增长 | Ripple 需要在规模和精度之间找到平衡点，Star-Sea 分层本质上就是对这个权衡的设计回应 |
| **推荐算法的嵌入模型** | TwHIN-BERT（社交媒体专用）优于通用 BERT | Ripple 在实现各平台 RecSys 时应优先使用领域专用嵌入模型 |
